#!/usr/bin/env python3
"""
gRPC å®¢æˆ·ç«¯äº¤äº’å¼æµ‹è¯•è„šæœ¬

å…è®¸ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ä¿¡æ¯è¿›è¡Œæµ‹è¯•ï¼š
- è‡ªå®šä¹‰è¾“å…¥æ•°æ®
- é€‰æ‹©ä¸åŒçš„æµ‹è¯•åœºæ™¯
- å®æ—¶æŸ¥çœ‹ç»“æœ
"""

import os
import sys
import time
import torch
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ grpc ä¹‹å‰ï¼‰
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnComm', 'src'))

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)

# æ³¨æ„ï¼šäº¤äº’å¼å®¢æˆ·ç«¯å¯ä»¥ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼Œå› ä¸ºå®ƒåªæ˜¯å‘é€è¯·æ±‚
# å¦‚æœéœ€è¦å¼‚æ­¥ç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨ client_comm_simple_async.py
from splitlearn_comm import GRPCComputeClient

# æµ‹è¯•é…ç½®
DEFAULT_SERVER = "localhost:50056"  # ç®€å•æœåŠ¡å™¨ç«¯å£
TIMEOUT = 30.0


def print_separator():
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 70)


def print_tensor_info(tensor, name="å¼ é‡"):
    """æ‰“å°å¼ é‡è¯¦ç»†ä¿¡æ¯"""
    print(f"\nğŸ“Š {name}ä¿¡æ¯:")
    print(f"   å½¢çŠ¶: {tensor.shape}")
    print(f"   æ•°æ®ç±»å‹: {tensor.dtype}")
    print(f"   æ•°æ®å¤§å°: {tensor.numel() * 4 / 1024:.2f} KB")
    print(f"   æœ€å°å€¼: {tensor.min().item():.6f}")
    print(f"   æœ€å¤§å€¼: {tensor.max().item():.6f}")
    print(f"   å¹³å‡å€¼: {tensor.mean().item():.6f}")
    print(f"   æ ‡å‡†å·®: {tensor.std().item():.6f}")


def create_custom_tensor():
    """åˆ›å»ºè‡ªå®šä¹‰å¼ é‡"""
    print_separator()
    print("ğŸ“ åˆ›å»ºè‡ªå®šä¹‰å¼ é‡")
    print_separator()
    
    print("\nè¯·é€‰æ‹©åˆ›å»ºæ–¹å¼ï¼š")
    print("1. éšæœºå¼ é‡ï¼ˆæŒ‡å®šå½¢çŠ¶ï¼‰")
    print("2. å…¨é›¶å¼ é‡ï¼ˆæŒ‡å®šå½¢çŠ¶ï¼‰")
    print("3. å…¨ä¸€å¼ é‡ï¼ˆæŒ‡å®šå½¢çŠ¶ï¼‰")
    print("4. æ‰‹åŠ¨è¾“å…¥æ•°å€¼ï¼ˆ1D å¼ é‡ï¼‰")
    print("5. ä½¿ç”¨é¢„è®¾å½¢çŠ¶")
    
    choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
    
    if choice == "1":
        # éšæœºå¼ é‡
        print("\nè¯·è¾“å…¥å½¢çŠ¶ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚: 1 10 768ï¼‰:")
        shape_str = input("å½¢çŠ¶: ").strip()
        try:
            shape = tuple(map(int, shape_str.split()))
            tensor = torch.randn(*shape)
            print(f"âœ“ åˆ›å»ºéšæœºå¼ é‡: {shape}")
            return tensor
        except Exception as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
            return None
    
    elif choice == "2":
        # å…¨é›¶å¼ é‡
        print("\nè¯·è¾“å…¥å½¢çŠ¶ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚: 1 10 768ï¼‰:")
        shape_str = input("å½¢çŠ¶: ").strip()
        try:
            shape = tuple(map(int, shape_str.split()))
            tensor = torch.zeros(*shape)
            print(f"âœ“ åˆ›å»ºå…¨é›¶å¼ é‡: {shape}")
            return tensor
        except Exception as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
            return None
    
    elif choice == "3":
        # å…¨ä¸€å¼ é‡
        print("\nè¯·è¾“å…¥å½¢çŠ¶ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚: 1 10 768ï¼‰:")
        shape_str = input("å½¢çŠ¶: ").strip()
        try:
            shape = tuple(map(int, shape_str.split()))
            tensor = torch.ones(*shape)
            print(f"âœ“ åˆ›å»ºå…¨ä¸€å¼ é‡: {shape}")
            return tensor
        except Exception as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
            return None
    
    elif choice == "4":
        # æ‰‹åŠ¨è¾“å…¥æ•°å€¼
        print("\nè¯·è¾“å…¥æ•°å€¼ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚: 1.0 2.0 3.0ï¼‰:")
        values_str = input("æ•°å€¼: ").strip()
        try:
            values = list(map(float, values_str.split()))
            tensor = torch.tensor(values)
            print(f"âœ“ åˆ›å»ºå¼ é‡: {tensor.shape}")
            return tensor
        except Exception as e:
            print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
            return None
    
    elif choice == "5":
        # é¢„è®¾å½¢çŠ¶
        print("\nè¯·é€‰æ‹©é¢„è®¾å½¢çŠ¶ï¼š")
        print("1. (1, 10, 768)  - å°å¼ é‡")
        print("2. (1, 20, 768)  - ä¸­ç­‰å¼ é‡")
        print("3. (2, 10, 768)  - æ‰¹é‡=2")
        print("4. (1, 5, 768)   - çŸ­åºåˆ—")
        print("5. (1, 50, 768)  - é•¿åºåˆ—")
        
        preset = input("è¯·é€‰æ‹© (1-5): ").strip()
        presets = {
            "1": (1, 10, 768),
            "2": (1, 20, 768),
            "3": (2, 10, 768),
            "4": (1, 5, 768),
            "5": (1, 50, 768),
        }
        
        if preset in presets:
            shape = presets[preset]
            tensor = torch.randn(*shape)
            print(f"âœ“ åˆ›å»ºéšæœºå¼ é‡: {shape}")
            return tensor
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return None
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return None


def send_single_request(client, input_tensor):
    """å‘é€å•ä¸ªè¯·æ±‚"""
    print_separator()
    print("ğŸ“¤ å‘é€è¯·æ±‚")
    print_separator()
    
    # æ˜¾ç¤ºè¾“å…¥æ•°æ®
    print_tensor_info(input_tensor, "è¾“å…¥")
    
    # å‘é€è¯·æ±‚
    print(f"\nğŸš€ æ­£åœ¨å‘é€è¯·æ±‚...")
    start_time = time.time()
    
    try:
        output = client.compute(input_tensor)
        total_time = (time.time() - start_time) * 1000
        
        print(f"âœ“ è¯·æ±‚æˆåŠŸï¼")
        
        # æ˜¾ç¤ºè¾“å‡ºæ•°æ®
        print_tensor_info(output, "è¾“å‡º")
        
        # éªŒè¯ç»“æœï¼ˆç®€å•æœåŠ¡å™¨ï¼šoutput = input * 2 + 1ï¼‰
        expected = input_tensor * 2 + 1
        if torch.allclose(output, expected, atol=1e-5):
            print(f"\nâœ… è®¡ç®—ç»“æœæ­£ç¡®: output = input * 2 + 1")
        else:
            print(f"\nâš ï¸  è®¡ç®—ç»“æœä¸ç¬¦åˆé¢„æœŸ")
            print(f"   é¢„æœŸèŒƒå›´: [{expected.min().item():.6f}, {expected.max().item():.6f}]")
            print(f"   å®é™…èŒƒå›´: [{output.min().item():.6f}, {output.max().item():.6f}]")
        
        # ä¼ è¾“ç»Ÿè®¡
        input_size_kb = input_tensor.numel() * 4 / 1024
        output_size_kb = output.numel() * 4 / 1024
        total_size_kb = input_size_kb + output_size_kb
        
        print(f"\nğŸ“¡ ä¼ è¾“ç»Ÿè®¡:")
        print(f"   å‘é€æ•°æ®: {input_size_kb:.2f} KB")
        print(f"   æ¥æ”¶æ•°æ®: {output_size_kb:.2f} KB")
        print(f"   æ€»ä¼ è¾“: {total_size_kb:.2f} KB")
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
        if total_time > 0:
            print(f"   ååé‡: {total_size_kb / (total_time / 1000):.2f} KB/s")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ è¯·æ±‚å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def send_multiple_requests(client):
    """å‘é€å¤šä¸ªè¯·æ±‚"""
    print_separator()
    print("ğŸ”„ å¤šæ¬¡è¯·æ±‚æµ‹è¯•")
    print_separator()
    
    num_requests = input("\nè¯·è¾“å…¥è¯·æ±‚æ•°é‡ (é»˜è®¤ 5): ").strip()
    num_requests = int(num_requests) if num_requests else 5
    
    print(f"\nå°†å‘é€ {num_requests} ä¸ªè¯·æ±‚...")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    print("\nè¯·é€‰æ‹©è¾“å…¥æ•°æ®ï¼š")
    print("1. æ¯æ¬¡ä½¿ç”¨ç›¸åŒçš„éšæœºå¼ é‡")
    print("2. æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºå¼ é‡")
    
    choice = input("è¯·é€‰æ‹© (1-2): ").strip()
    
    if choice == "1":
        # ç›¸åŒçš„å¼ é‡
        test_input = torch.randn(1, 10, 768)
        print(f"âœ“ ä½¿ç”¨å›ºå®šå¼ é‡: {test_input.shape}")
    elif choice == "2":
        # ä¸åŒçš„å¼ é‡
        test_input = None
        print("âœ“ æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºå¼ é‡")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤")
        test_input = torch.randn(1, 10, 768)
    
    successes = 0
    total_time = 0.0
    
    for i in range(num_requests):
        print(f"\n--- è¯·æ±‚ {i+1}/{num_requests} ---")
        
        if test_input is None:
            # æ¯æ¬¡åˆ›å»ºæ–°çš„éšæœºå¼ é‡
            current_input = torch.randn(1, 10, 768)
        else:
            current_input = test_input
        
        start_time = time.time()
        try:
            output = client.compute(current_input)
            elapsed = (time.time() - start_time) * 1000
            total_time += elapsed
            successes += 1
            print(f"   âœ“ æˆåŠŸ (è€—æ—¶: {elapsed:.2f} ms)")
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   æˆåŠŸ: {successes}/{num_requests}")
    if successes > 0:
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
        print(f"   å¹³å‡è€—æ—¶: {total_time/successes:.2f} ms")


def show_statistics(client):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print_separator()
    print("ğŸ“Š å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯")
    print_separator()
    
    stats = client.get_statistics()
    
    print(f"\næ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
    print(f"å¹³å‡ç½‘ç»œæ—¶é—´: {stats.get('avg_network_time_ms', 0):.2f} ms")
    print(f"å¹³å‡è®¡ç®—æ—¶é—´: {stats.get('avg_compute_time_ms', 0):.2f} ms")
    print(f"å¹³å‡æ€»æ—¶é—´: {stats.get('avg_total_time_ms', 0):.2f} ms")


def show_service_info(client):
    """æ˜¾ç¤ºæœåŠ¡ä¿¡æ¯"""
    print_separator()
    print("â„¹ï¸  æœåŠ¡å™¨ä¿¡æ¯")
    print_separator()
    
    try:
        info = client.get_service_info()
        
        if info:
            print(f"\næœåŠ¡å: {info.get('service_name', 'N/A')}")
            print(f"ç‰ˆæœ¬: {info.get('version', 'N/A')}")
            print(f"è®¾å¤‡: {info.get('device', 'N/A')}")
            print(f"æ€»è¯·æ±‚æ•°: {info.get('total_requests', 0)}")
            print(f"è¿è¡Œæ—¶é—´: {info.get('uptime_seconds', 0):.1f} ç§’")
        else:
            print("âŒ æ— æ³•è·å–æœåŠ¡å™¨ä¿¡æ¯")
    except Exception as e:
        print(f"âŒ è·å–æœåŠ¡å™¨ä¿¡æ¯å¤±è´¥: {e}")


def main_menu(client):
    """ä¸»èœå•"""
    while True:
        print_separator()
        print("ğŸ“‹ ä¸»èœå•")
        print_separator()
        
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. å‘é€å•ä¸ªè¯·æ±‚ï¼ˆä½¿ç”¨è‡ªå®šä¹‰è¾“å…¥ï¼‰")
        print("2. å‘é€å•ä¸ªè¯·æ±‚ï¼ˆä½¿ç”¨é¢„è®¾è¾“å…¥ï¼‰")
        print("3. å‘é€å¤šä¸ªè¯·æ±‚")
        print("4. æŸ¥çœ‹å®¢æˆ·ç«¯ç»Ÿè®¡")
        print("5. æŸ¥çœ‹æœåŠ¡å™¨ä¿¡æ¯")
        print("6. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (1-6): ").strip()
        
        if choice == "1":
            # è‡ªå®šä¹‰è¾“å…¥
            input_tensor = create_custom_tensor()
            if input_tensor is not None:
                send_single_request(client, input_tensor)
        
        elif choice == "2":
            # é¢„è®¾è¾“å…¥
            input_tensor = torch.randn(1, 10, 768)
            print(f"\nâœ“ ä½¿ç”¨é¢„è®¾è¾“å…¥: {input_tensor.shape}")
            send_single_request(client, input_tensor)
        
        elif choice == "3":
            # å¤šæ¬¡è¯·æ±‚
            send_multiple_requests(client)
        
        elif choice == "4":
            # ç»Ÿè®¡ä¿¡æ¯
            show_statistics(client)
        
        elif choice == "5":
            # æœåŠ¡å™¨ä¿¡æ¯
            show_service_info(client)
        
        elif choice == "6":
            # é€€å‡º
            print("\nğŸ‘‹ å†è§ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
        
        # ç­‰å¾…ç”¨æˆ·ç¡®è®¤
        input("\næŒ‰ Enter ç»§ç»­...")


def main():
    print("\n" + "=" * 70)
    print("ğŸ’» gRPC å®¢æˆ·ç«¯äº¤äº’å¼æµ‹è¯•")
    print("=" * 70)
    
    # è·å–æœåŠ¡å™¨åœ°å€
    server_address = input(f"\nè¯·è¾“å…¥æœåŠ¡å™¨åœ°å€ (é»˜è®¤: {DEFAULT_SERVER}): ").strip()
    if not server_address:
        server_address = DEFAULT_SERVER
    
    print(f"\nğŸ“¡ è¿æ¥æœåŠ¡å™¨: {server_address}")
    print("   æ­£åœ¨è¿æ¥...")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = GRPCComputeClient(
        server_address=server_address,
        timeout=TIMEOUT
    )
    
    # è¿æ¥æœåŠ¡å™¨
    if not client.connect():
        print("   âŒ è¿æ¥å¤±è´¥ï¼")
        print(f"\nğŸ’¡ è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ:")
        print(f"   python testcode/server_comm_simple.py")
        return 1
    
    print("   âœ“ è¿æ¥æˆåŠŸï¼")
    
    try:
        # æ˜¾ç¤ºä¸»èœå•
        main_menu(client)
    finally:
        print("\nğŸ”Œ å…³é—­è¿æ¥...")
        client.close()
        print("   âœ“ è¿æ¥å·²å…³é—­")
    
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

