#!/usr/bin/env python3
"""
æµ‹è¯•æ¨¡å‹ä»ç¡¬ç›˜åŠ è½½åˆ°å†…å­˜çš„åŠŸèƒ½

åªæµ‹è¯•æ¨¡å‹åŠ è½½ï¼Œä¸æ¶‰åŠ gRPC æœåŠ¡å™¨æˆ–å®¢æˆ·ç«¯
"""

import os
import sys
import time
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ torch ä¹‹å‰ï¼‰
os.environ.setdefault('OMP_NUM_THREADS', '1')
os.environ.setdefault('MKL_NUM_THREADS', '1')
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')

# æ·»åŠ è·¯å¾„ï¼ˆå¦‚æœéœ€è¦å¯¼å…¥ splitlearn_coreï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnCore', 'src'))

# æµ‹è¯•é…ç½®
MODEL_FILES = [
    "gpt2_trunk_full.pt",
    "gpt2_bottom_cached.pt",
    "gpt2_top_cached.pt",
]


def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} TB"


def get_model_info(model):
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # è®¡ç®—æ¨¡å‹å¤§å°ï¼ˆå‚æ•°æ•°é‡ * 4 å­—èŠ‚ï¼Œå‡è®¾ float32ï¼‰
    model_size_mb = total_params * 4 / (1024 * 1024)
    
    return {
        "type": type(model).__name__,
        "total_params": total_params,
        "trainable_params": trainable_params,
        "model_size_mb": model_size_mb,
    }


def test_load_model(model_path):
    """æµ‹è¯•åŠ è½½å•ä¸ªæ¨¡å‹"""
    print("\n" + "=" * 70)
    print(f"ğŸ“¦ æµ‹è¯•åŠ è½½æ¨¡å‹: {os.path.basename(model_path)}")
    print("=" * 70)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    # 2. æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    file_size = os.path.getsize(model_path)
    print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯:")
    print(f"   è·¯å¾„: {model_path}")
    print(f"   å¤§å°: {format_size(file_size)}")
    print(f"   çŠ¶æ€: æ–‡ä»¶åœ¨ç£ç›˜ä¸Šï¼ˆæœªåŠ è½½åˆ°å†…å­˜ï¼‰")
    
    # 3. åŠ è½½æ¨¡å‹
    print(f"\nâ³ å¼€å§‹åŠ è½½æ¨¡å‹åˆ°å†…å­˜...")
    print(f"   æ‰§è¡Œ: torch.load('{os.path.basename(model_path)}', map_location='cpu')")
    
    start_time = time.time()
    
    try:
        # åŠ è½½æ¨¡å‹
        model = torch.load(model_path, map_location='cpu', weights_only=False)
        
        load_time = time.time() - start_time
        
        print(f"   âœ“ åŠ è½½æˆåŠŸï¼")
        print(f"   âœ“ è€—æ—¶: {load_time:.2f} ç§’")
        
        # 4. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        model_info = get_model_info(model)
        print(f"   ç±»å‹: {model_info['type']}")
        print(f"   æ€»å‚æ•°é‡: {model_info['total_params']:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {model_info['trainable_params']:,}")
        print(f"   æ¨¡å‹å¤§å°ï¼ˆä¼°ç®—ï¼‰: {model_info['model_size_mb']:.2f} MB")
        
        # 5. è®¾ç½®è¯„ä¼°æ¨¡å¼
        print(f"\nğŸ”§ è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼...")
        model.eval()
        print(f"   âœ“ model.eval() å®Œæˆ")
        
        # 6. æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸æ¨ç†ï¼ˆå¯é€‰ï¼‰
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½...")
        try:
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•è¾“å…¥ï¼ˆå‡è®¾æ˜¯ GPT-2 trunk çš„è¾“å…¥æ ¼å¼ï¼‰
            # GPT-2 trunk é€šå¸¸æ¥å— [batch, seq_len, hidden_dim] æ ¼å¼
            test_input = torch.randn(1, 5, 768)  # å°è¾“å…¥ç”¨äºæµ‹è¯•
            
            with torch.no_grad():
                output = model(test_input)
            
            print(f"   âœ“ æ¨ç†æµ‹è¯•æˆåŠŸ")
            print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # æ˜¾ç¤ºè¾“å‡ºç»Ÿè®¡
            print(f"   è¾“å‡ºç»Ÿè®¡:")
            print(f"     æœ€å°å€¼: {output.min().item():.6f}")
            print(f"     æœ€å¤§å€¼: {output.max().item():.6f}")
            print(f"     å¹³å‡å€¼: {output.mean().item():.6f}")
            
        except Exception as e:
            print(f"   âš ï¸  æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
            print(f"   ï¼ˆè¿™å¯èƒ½æ˜¯å› ä¸ºè¾“å…¥æ ¼å¼ä¸æ­£ç¡®ï¼Œä½†ä¸å½±å“åŠ è½½æµ‹è¯•ï¼‰")
        
        # 7. å†…å­˜ä½¿ç”¨æƒ…å†µ
        print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨æƒ…å†µ:")
        print(f"   æ–‡ä»¶å¤§å°ï¼ˆç£ç›˜ï¼‰: {format_size(file_size)}")
        print(f"   æ¨¡å‹å¤§å°ï¼ˆå†…å­˜ä¼°ç®—ï¼‰: {format_size(model_info['model_size_mb'] * 1024 * 1024)}")
        print(f"   åŠ è½½æ—¶é—´: {load_time:.2f} ç§’")
        if load_time > 0:
            print(f"   åŠ è½½é€Ÿåº¦: {file_size / (1024 * 1024) / load_time:.2f} MB/s")
        
        print("\n" + "=" * 70)
        print("âœ… æ¨¡å‹åŠ è½½æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ¨¡å‹ä»ç¡¬ç›˜åŠ è½½åˆ°å†…å­˜æµ‹è¯•")
    print("=" * 70)
    print("\nğŸ“‹ æµ‹è¯•ç›®æ ‡:")
    print("   1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    print("   2. ä»ç£ç›˜åŠ è½½æ¨¡å‹åˆ°å†…å­˜")
    print("   3. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯")
    print("   4. æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸æ¨ç†")
    print("   5. æ˜¾ç¤ºåŠ è½½æ—¶é—´å’Œæ€§èƒ½ç»Ÿè®¡")
    
    # è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    model_files = [os.path.join(current_dir, f) for f in MODEL_FILES]
    
    # åªæµ‹è¯•å­˜åœ¨çš„æ–‡ä»¶
    existing_files = [f for f in model_files if os.path.exists(f)]
    
    if not existing_files:
        print(f"\nâŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
        print(f"   æŸ¥æ‰¾è·¯å¾„: {current_dir}")
        print(f"   æŸ¥æ‰¾æ–‡ä»¶: {', '.join(MODEL_FILES)}")
        return 1
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(existing_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")
    for f in existing_files:
        print(f"   - {os.path.basename(f)}")
    
    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
    results = []
    for model_file in existing_files:
        success = test_load_model(model_file)
        results.append((os.path.basename(model_file), success))
        time.sleep(1)  # çŸ­æš‚ä¼‘æ¯
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    for model_name, success in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"   {status}: {model_name}")
    
    success_count = sum(1 for _, s in results if s)
    print(f"\næ€»è®¡: {success_count}/{len(results)} ä¸ªæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    return 0 if success_count == len(results) else 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

