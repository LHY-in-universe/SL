#!/usr/bin/env python3
"""
æµ‹è¯• gRPC å®¢æˆ·ç«¯åŠŸèƒ½

æµ‹è¯•å†…å®¹ï¼š
1. å®¢æˆ·ç«¯åˆ›å»ºå’Œè¿æ¥
2. å¥åº·æ£€æŸ¥
3. æœåŠ¡ä¿¡æ¯æŸ¥è¯¢
4. è®¡ç®—è¯·æ±‚
5. å¤šæ¬¡è¯·æ±‚
6. é”™è¯¯å¤„ç†
7. ç»Ÿè®¡ä¿¡æ¯
"""

import os
import sys
import time
import threading
import torch
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ grpc ä¹‹å‰ï¼‰
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'
os.environ.setdefault('OMP_NUM_THREADS', '1')
os.environ.setdefault('MKL_NUM_THREADS', '1')
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnComm', 'src'))
sys.path.insert(0, os.path.join(project_root, 'SplitLearnCore', 'src'))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

from splitlearn_comm import GRPCComputeClient, GRPCComputeServer
from splitlearn_comm.core import ModelComputeFunction

# æµ‹è¯•é…ç½®
TEST_PORT = 50054
TEST_HOST = "localhost"
MODEL_PATH = os.path.join(current_dir, "gpt2_trunk_full.pt")

# å…¨å±€æœåŠ¡å™¨å˜é‡ï¼ˆç”¨äºåå°è¿è¡Œï¼‰
_server = None
_server_thread = None


def start_test_server():
    """å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨ï¼ˆåå°ï¼‰"""
    global _server, _server_thread
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
        return False
    
    # åŠ è½½æ¨¡å‹
    model = torch.load(MODEL_PATH, map_location='cpu', weights_only=False)
    model.eval()
    
    # åˆ›å»ºè®¡ç®—å‡½æ•°
    compute_fn = ModelComputeFunction(
        model=model,
        device="cpu",
        model_name="gpt2-trunk-test"
    )
    
    # åˆ›å»ºæœåŠ¡å™¨
    _server = GRPCComputeServer(
        compute_fn=compute_fn,
        host="0.0.0.0",
        port=TEST_PORT,
        max_workers=1
    )
    
    def run_server():
        _server.start()
        _server.wait_for_termination()
    
    _server_thread = threading.Thread(target=run_server, daemon=True)
    _server_thread.start()
    
    # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    time.sleep(3)
    return True


def stop_test_server():
    """åœæ­¢æµ‹è¯•æœåŠ¡å™¨"""
    global _server
    if _server:
        try:
            _server.stop(grace=2)
        except:
            pass


def test_client_creation():
    """æµ‹è¯• 1: å®¢æˆ·ç«¯åˆ›å»º"""
    print("=" * 70)
    print("æµ‹è¯• 1: å®¢æˆ·ç«¯åˆ›å»º")
    print("=" * 70)
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        print(f"\nåˆ›å»º gRPC å®¢æˆ·ç«¯ (æœåŠ¡å™¨: {TEST_HOST}:{TEST_PORT})...")
        client = GRPCComputeClient(
            server_address=f"{TEST_HOST}:{TEST_PORT}",
            timeout=10.0
        )
        print("âœ“ å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥å®¢æˆ·ç«¯å±æ€§
        print(f"\nå®¢æˆ·ç«¯ä¿¡æ¯:")
        print(f"  æœåŠ¡å™¨åœ°å€: {client.server_address}")
        print(f"  è¶…æ—¶æ—¶é—´: {client.timeout} ç§’")
        print(f"  æœ€å¤§æ¶ˆæ¯é•¿åº¦: {client.max_message_length / (1024*1024):.1f} MB")
        
        return client
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_client_connection(client):
    """æµ‹è¯• 2: å®¢æˆ·ç«¯è¿æ¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: å®¢æˆ·ç«¯è¿æ¥")
    print("=" * 70)
    
    try:
        # è¿æ¥æœåŠ¡å™¨
        print("\nè¿æ¥æœåŠ¡å™¨...")
        if client.connect():
            print("âœ“ è¿æ¥æˆåŠŸ")
            
            # æ£€æŸ¥è¿æ¥çŠ¶æ€
            print(f"\nè¿æ¥çŠ¶æ€:")
            print(f"  å·²è¿æ¥: {client.channel is not None}")
            print(f"  Stub å·²åˆ›å»º: {client.stub is not None}")
            
            return True
        else:
            print("âŒ è¿æ¥å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_health_check(client):
    """æµ‹è¯• 3: å¥åº·æ£€æŸ¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: å¥åº·æ£€æŸ¥")
    print("=" * 70)
    
    try:
        print("\næ‰§è¡Œå¥åº·æ£€æŸ¥...")
        is_healthy = client.health_check()
        
        if is_healthy:
            print("âœ“ æœåŠ¡å™¨å¥åº·")
        else:
            print("âš ï¸  æœåŠ¡å™¨ä¸å¥åº·")
        
        return is_healthy
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_service_info(client):
    """æµ‹è¯• 4: æœåŠ¡ä¿¡æ¯æŸ¥è¯¢"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: æœåŠ¡ä¿¡æ¯æŸ¥è¯¢")
    print("=" * 70)
    
    try:
        print("\nè·å–æœåŠ¡ä¿¡æ¯...")
        info = client.get_service_info()
        
        print("âœ“ æœåŠ¡ä¿¡æ¯è·å–æˆåŠŸ")
        print(f"\næœåŠ¡ä¿¡æ¯:")
        print(f"  æœåŠ¡å: {info.get('service_name', 'N/A')}")
        print(f"  ç‰ˆæœ¬: {info.get('version', 'N/A')}")
        print(f"  è®¾å¤‡: {info.get('device', 'N/A')}")
        print(f"  æ€»è¯·æ±‚æ•°: {info.get('total_requests', 0)}")
        print(f"  è¿è¡Œæ—¶é—´: {info.get('uptime_seconds', 0):.1f} ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_compute_request(client):
    """æµ‹è¯• 5: è®¡ç®—è¯·æ±‚"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 5: è®¡ç®—è¯·æ±‚")
    print("=" * 70)
    
    try:
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(1, 10, 768)
        print(f"\næµ‹è¯•è¾“å…¥:")
        print(f"  å½¢çŠ¶: {test_input.shape}")
        print(f"  å¤§å°: {test_input.numel() * 4 / 1024:.2f} KB")
        
        # å‘é€è®¡ç®—è¯·æ±‚
        print("\nå‘é€è®¡ç®—è¯·æ±‚...")
        start_time = time.time()
        output = client.compute(test_input)
        elapsed = time.time() - start_time
        
        print(f"âœ“ è®¡ç®—å®Œæˆ")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  è¾“å‡ºå¤§å°: {output.numel() * 4 / 1024:.2f} KB")
        print(f"  æ€»è€—æ—¶: {elapsed*1000:.2f} ms")
        
        # éªŒè¯è¾“å‡º
        if output.shape == test_input.shape:
            print("âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®")
        else:
            print(f"âš ï¸  è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸ: {output.shape} (æœŸæœ›: {test_input.shape})")
        
        # æµ‹è¯•ä¸åŒå½¢çŠ¶
        print("\næµ‹è¯•ä¸åŒå½¢çŠ¶çš„è¾“å…¥...")
        test_cases = [
            (1, 5, 768),   # çŸ­åºåˆ—
            (1, 20, 768),  # é•¿åºåˆ—
        ]
        
        for i, shape in enumerate(test_cases, 1):
            test_input = torch.randn(*shape)
            try:
                output = client.compute(test_input)
                if output.shape == shape:
                    print(f"  âœ“ æµ‹è¯• {i}: {shape} â†’ {output.shape}")
                else:
                    print(f"  âš ï¸  æµ‹è¯• {i}: {shape} â†’ {output.shape}")
            except Exception as e:
                print(f"  âŒ æµ‹è¯• {i} å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multiple_requests(client):
    """æµ‹è¯• 6: å¤šæ¬¡è¯·æ±‚"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 6: å¤šæ¬¡è¯·æ±‚")
    print("=" * 70)
    
    try:
        num_requests = 5
        successes = 0
        total_time = 0.0
        
        print(f"\nå‘é€ {num_requests} ä¸ªè¯·æ±‚...")
        
        for i in range(num_requests):
            test_input = torch.randn(1, 5, 768)
            try:
                start_time = time.time()
                output = client.compute(test_input)
                elapsed = time.time() - start_time
                total_time += elapsed
                successes += 1
                print(f"  è¯·æ±‚ {i+1}/{num_requests}: âœ“ (è€—æ—¶: {elapsed*1000:.2f} ms)")
            except Exception as e:
                print(f"  è¯·æ±‚ {i+1}/{num_requests}: âŒ ({e})")
        
        avg_time = total_time / successes if successes > 0 else 0
        print(f"\næ€»ç»“:")
        print(f"  æˆåŠŸ: {successes}/{num_requests}")
        print(f"  å¹³å‡è€—æ—¶: {avg_time*1000:.2f} ms")
        print(f"  æ€»è€—æ—¶: {total_time*1000:.2f} ms")
        
        return successes == num_requests
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_statistics(client):
    """æµ‹è¯• 7: ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 7: ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 70)
    
    try:
        print("\nè·å–å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯...")
        stats = client.get_statistics()
        
        print("âœ“ ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
        print(f"\nç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
        print(f"  æˆåŠŸè¯·æ±‚: {stats.get('successful_requests', 0)}")
        print(f"  å¤±è´¥è¯·æ±‚: {stats.get('failed_requests', 0)}")
        print(f"  å¹³å‡ç½‘ç»œæ—¶é—´: {stats.get('avg_network_time_ms', 0):.2f} ms")
        print(f"  å¹³å‡è®¡ç®—æ—¶é—´: {stats.get('avg_compute_time_ms', 0):.2f} ms")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_error_handling(client):
    """æµ‹è¯• 8: é”™è¯¯å¤„ç†"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 8: é”™è¯¯å¤„ç†")
    print("=" * 70)
    
    try:
        # æµ‹è¯•è¿æ¥æ–­å¼€åçš„è¡Œä¸º
        print("\næµ‹è¯•è¿æ¥æ–­å¼€...")
        client.close()
        
        try:
            output = client.compute(torch.randn(1, 5, 768))
            print("âš ï¸  è¿æ¥æ–­å¼€åä»èƒ½è®¡ç®—ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰")
            return False
        except Exception as e:
            print(f"âœ“ æ­£ç¡®æ£€æµ‹åˆ°è¿æ¥æ–­å¼€: {type(e).__name__}")
            return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_context_manager():
    """æµ‹è¯• 9: ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 9: å®¢æˆ·ç«¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
    print("=" * 70)
    
    try:
        print("\nä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨...")
        with GRPCComputeClient(
            server_address=f"{TEST_HOST}:{TEST_PORT}",
            timeout=10.0
        ) as client:
            if client.connect():
                print("âœ“ å®¢æˆ·ç«¯åœ¨ä¸Šä¸‹æ–‡ä¸­è¿æ¥æˆåŠŸ")
                
                # æ‰§è¡Œä¸€æ¬¡è®¡ç®—
                test_input = torch.randn(1, 5, 768)
                output = client.compute(test_input)
                print(f"âœ“ è®¡ç®—æˆåŠŸ: {test_input.shape} â†’ {output.shape}")
            else:
                print("âŒ è¿æ¥å¤±è´¥")
                return False
        
        print("âœ“ ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡ºï¼Œå®¢æˆ·ç«¯è‡ªåŠ¨å…³é—­")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 70)
    print("gRPC å®¢æˆ·ç«¯åŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    print(f"\næµ‹è¯•é…ç½®:")
    print(f"  æœåŠ¡å™¨åœ°å€: {TEST_HOST}:{TEST_PORT}")
    print(f"  æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}")
    print()
    
    # å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨
    print("å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨...")
    if not start_test_server():
        print("âŒ æ— æ³•å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨")
        return 1
    
    print("âœ“ æµ‹è¯•æœåŠ¡å™¨å·²å¯åŠ¨")
    time.sleep(2)
    
    results = {}
    
    try:
        # æµ‹è¯• 1: å®¢æˆ·ç«¯åˆ›å»º
        client = test_client_creation()
        if client is None:
            print("\nâŒ å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return 1
        
        results['creation'] = client is not None
        
        # æµ‹è¯• 2: å®¢æˆ·ç«¯è¿æ¥
        results['connection'] = test_client_connection(client)
        
        # æµ‹è¯• 3: å¥åº·æ£€æŸ¥
        results['health_check'] = test_health_check(client)
        
        # æµ‹è¯• 4: æœåŠ¡ä¿¡æ¯
        results['service_info'] = test_service_info(client)
        
        # æµ‹è¯• 5: è®¡ç®—è¯·æ±‚
        results['compute'] = test_compute_request(client)
        
        # æµ‹è¯• 6: å¤šæ¬¡è¯·æ±‚
        results['multiple'] = test_multiple_requests(client)
        
        # æµ‹è¯• 7: ç»Ÿè®¡ä¿¡æ¯
        results['statistics'] = test_statistics(client)
        
        # æµ‹è¯• 8: é”™è¯¯å¤„ç†
        results['error_handling'] = test_error_handling(client)
        
        # æµ‹è¯• 9: ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        results['context_manager'] = test_context_manager()
        
    finally:
        # åœæ­¢æµ‹è¯•æœåŠ¡å™¨
        print("\nåœæ­¢æµ‹è¯•æœåŠ¡å™¨...")
        stop_test_server()
        time.sleep(1)
        print("âœ“ æµ‹è¯•æœåŠ¡å™¨å·²åœæ­¢")
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    for test_name, result in results.items():
        status = "âœ“ é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name:20s}: {status}")
    
    passed = sum(results.values())
    total = len(results)
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼gRPC å®¢æˆ·ç«¯åŠŸèƒ½æ­£å¸¸ï¼")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        stop_test_server()
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        stop_test_server()
        sys.exit(1)

