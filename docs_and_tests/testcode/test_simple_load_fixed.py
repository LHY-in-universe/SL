#!/usr/bin/env python3
"""
ç®€å•çš„æ¨¡å‹åŠ è½½æµ‹è¯• - ä½¿ç”¨ core åº“ï¼ˆä¿®å¤ç‰ˆï¼‰

âœ… ä¿®å¤è¦ç‚¹ï¼šåœ¨å¯¼å…¥ä»»ä½•æ¨¡å—ä¹‹å‰å…ˆè®¾ç½®ç¯å¢ƒå˜é‡
"""

# ============================================================================
# âœ… ç¬¬ä¸€æ­¥ï¼šå…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰ï¼ï¼‰
# ============================================================================
import os
import sys

print("[0/10] è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ä»»ä½•æ¨¡å—ä¹‹å‰ï¼ï¼‰")
os.environ.setdefault('OMP_NUM_THREADS', '1')
print("   âœ“ OMP_NUM_THREADS = 1")
os.environ.setdefault('MKL_NUM_THREADS', '1')
print("   âœ“ MKL_NUM_THREADS = 1")
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')
print("   âœ“ NUMEXPR_NUM_THREADS = 1")

# ============================================================================
# ç¬¬äºŒæ­¥ï¼šæ·»åŠ è·¯å¾„
# ============================================================================
print("\n[1/10] æ·»åŠ  SplitLearnCore è·¯å¾„...")
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
core_src_path = os.path.join(project_root, 'SplitLearnCore', 'src')
sys.path.insert(0, core_src_path)
print(f"   âœ“ è·¯å¾„å·²æ·»åŠ : {core_src_path}")

# ============================================================================
# ç¬¬ä¸‰æ­¥ï¼šç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯¼å…¥ splitlearn_core
# ============================================================================
print("\n[2/10] å¯¼å…¥ splitlearn_coreï¼ˆç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼Œä¸ä¼šæœ‰ mutex è­¦å‘Šï¼‰...")

print("   [2.1] å¯¼å…¥ splitlearn_core...")
import splitlearn_core
print("   âœ“ splitlearn_core å¯¼å…¥æˆåŠŸ")

print("   [2.2] å¯¼å…¥ splitlearn_core.models...")
import splitlearn_core.models
print("   âœ“ splitlearn_core.models å¯¼å…¥æˆåŠŸ")

print("   [2.3] å¯¼å…¥ splitlearn_core.models.gpt2...")
import splitlearn_core.models.gpt2
print("   âœ“ splitlearn_core.models.gpt2 å¯¼å…¥æˆåŠŸ")

print("   [2.4] å¯¼å…¥ GPT2TrunkModel...")
from splitlearn_core.models.gpt2 import GPT2TrunkModel
print("   âœ“ GPT2TrunkModel å¯¼å…¥æˆåŠŸï¼")

# ============================================================================
# ç¬¬å››æ­¥ï¼šå¯¼å…¥å…¶ä»–åº“
# ============================================================================
print("\n[3/10] å¯¼å…¥å…¶ä»–åº“...")
import time
print("   âœ“ time")

import torch
print("   âœ“ torch (ç‰ˆæœ¬: {})".format(torch.__version__))

from transformers import GPT2Config
print("   âœ“ transformers")

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    return f"{size_bytes / (1024*1024):.2f} MB"

def main():
    print("\n" + "=" * 70)
    print("ğŸ§ª ç®€å•æ¨¡å‹åŠ è½½æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("=" * 70)

    # æµ‹è¯•æ–‡ä»¶
    model_path = os.path.join(current_dir, "gpt2_trunk_full.pt")

    # 1. æ£€æŸ¥æ–‡ä»¶
    print(f"\nğŸ“ æ£€æŸ¥æ–‡ä»¶: {os.path.basename(model_path)}")
    if not os.path.exists(model_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print(f"\næç¤ºï¼šè¯·å…ˆè¿è¡Œç›¸åº”çš„è„šæœ¬æ¥åˆ›å»ºæ¨¡å‹æ–‡ä»¶")
        return 1

    file_size = os.path.getsize(model_path)
    print(f"   âœ“ æ–‡ä»¶å­˜åœ¨")
    print(f"   âœ“ æ–‡ä»¶å¤§å°: {format_size(file_size)}")

    # 2. æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨ torch.load()
    print(f"\n" + "-" * 70)
    print("æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨ torch.load()")
    print("-" * 70)

    print(f"\nâ³ å¼€å§‹åŠ è½½ï¼ˆtorch.loadï¼‰...")
    print(f"   è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

    start_time = time.time()
    try:
        model = torch.load(model_path, map_location='cpu', weights_only=False)
        load_time = time.time() - start_time

        print(f"\n   âœ“ åŠ è½½æˆåŠŸï¼")
        print(f"   âœ“ è€—æ—¶: {load_time:.2f} ç§’")
        print(f"   âœ“ æ¨¡å‹ç±»å‹: {type(model).__name__}")

        # æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   âœ“ å‚æ•°é‡: {total_params:,}")
        print(f"   âœ“ æ¨¡å‹å¤§å°: {format_size(total_params * 4)}")

        # æµ‹è¯•æ¨ç†
        print(f"\nğŸ§ª æµ‹è¯•æ¨ç†...")
        model.eval()
        test_input = torch.randn(1, 5, 768)
        with torch.no_grad():
            output = model(test_input)
        print(f"   âœ“ æ¨ç†æˆåŠŸ")
        print(f"   è¾“å…¥: {test_input.shape} -> è¾“å‡º: {output.shape}")

        method1_success = True

    except Exception as e:
        print(f"\n   âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        method1_success = False

    # 3. æ–¹æ³• 2: ä½¿ç”¨ core åº“åˆ›å»ºæ¨¡å‹å®ä¾‹
    print(f"\n" + "-" * 70)
    print("æ–¹æ³• 2: ä½¿ç”¨ SplitLearnCore æ¨¡å‹ç±»")
    print("-" * 70)

    print(f"\nâ³ åˆ›å»ºæ¨¡å‹å®ä¾‹...")
    try:
        config = GPT2Config()
        model_instance = GPT2TrunkModel(
            config=config,
            start_layer=2,
            end_layer=10
        )
        print(f"   âœ“ æ¨¡å‹å®ä¾‹åˆ›å»ºæˆåŠŸ")
        print(f"   âœ“ ç±»å‹: {type(model_instance).__name__}")

        # å°è¯•åŠ è½½ state_dictï¼ˆå¦‚æœæ–‡ä»¶åŒ…å« state_dictï¼‰
        print(f"\nâ³ å°è¯•åŠ è½½ state_dict...")
        loaded_data = torch.load(model_path, map_location='cpu', weights_only=False)

        if isinstance(loaded_data, dict):
            print(f"   âœ“ æ–‡ä»¶åŒ…å« state_dict")
            model_instance.load_state_dict(loaded_data, strict=False)
            print(f"   âœ“ state_dict åŠ è½½æˆåŠŸ")
        else:
            print(f"   â„¹ï¸  æ–‡ä»¶åŒ…å«å®Œæ•´æ¨¡å‹å¯¹è±¡ï¼Œä¸æ˜¯ state_dict")
            print(f"   ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰")

        method2_success = True

    except Exception as e:
        print(f"\n   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        method2_success = False

    # æ€»ç»“
    print(f"\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    print(f"   æ–¹æ³• 1 (torch.load): {'âœ… æˆåŠŸ' if method1_success else 'âŒ å¤±è´¥'}")
    print(f"   æ–¹æ³• 2 (core åº“): {'âœ… æˆåŠŸ' if method2_success else 'âŒ å¤±è´¥'}")

    if method1_success or method2_success:
        print(f"\nâœ… è‡³å°‘æœ‰ä¸€ç§æ–¹æ³•æˆåŠŸï¼Œæ¨¡å‹åŠ è½½åŠŸèƒ½æ­£å¸¸ï¼")
    else:
        print(f"\nâŒ ä¸¤ç§æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

    return 0 if (method1_success or method2_success) else 1

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
