"""
æµ‹è¯•å¢å¼ºçš„å®¢æˆ·ç«¯UI

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å®¢æˆ·ç«¯æ–°å¢çš„ç›‘æ§åŠŸèƒ½ï¼š
1. å®æ—¶æ—¥å¿—æ˜¾ç¤º
2. æœåŠ¡å™¨é€šä¿¡å»¶è¿Ÿç»Ÿè®¡ï¼ˆP95/P99ç­‰ï¼‰
3. å»¶è¿Ÿåˆ†å¸ƒå’Œè¶‹åŠ¿å›¾

æ³¨æ„ï¼šéœ€è¦å…ˆå¯åŠ¨æœåŠ¡ç«¯æ‰èƒ½è¿è¡Œæ­¤æµ‹è¯•
"""

import torch
from splitlearn_comm import GRPCComputeClient
from splitlearn_comm.ui import ClientUI


def create_mock_models():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡å‹"""
    # ç®€å•çš„ bottom æ¨¡å‹
    bottom_model = torch.nn.Sequential(
        torch.nn.Linear(10, 20),
        torch.nn.ReLU()
    )
    bottom_model.eval()

    # ç®€å•çš„ top æ¨¡å‹ï¼ˆå¸¦ logits å±æ€§ï¼‰
    class TopModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear = torch.nn.Linear(20, 100)  # å‡è®¾è¯æ±‡è¡¨å¤§å°ä¸º100

        def forward(self, x):
            logits = self.linear(x)
            # è¿”å›ä¸€ä¸ªå¸¦ logits å±æ€§çš„å¯¹è±¡
            class Output:
                def __init__(self, logits):
                    self.logits = logits
            return Output(logits)

    top_model = TopModel()
    top_model.eval()

    return bottom_model, top_model


def create_mock_tokenizer():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ tokenizer"""
    class MockTokenizer:
        def __init__(self):
            self.eos_token_id = 2
            self.vocab = ["<pad>", "<unk>", "<eos>"] + [f"word_{i}" for i in range(97)]

        def encode(self, text, return_tensors=None):
            # ç®€å•åœ°è¿”å›ä¸€äº›éšæœº token ids
            if return_tensors == "pt":
                return torch.randint(3, 100, (1, 5))
            return [3, 4, 5, 6, 7]

        def decode(self, token_ids):
            # ç®€å•åœ°è¿”å›ä¸€ä¸ªå•è¯
            if isinstance(token_ids, torch.Tensor):
                token_ids = token_ids.tolist()
            if isinstance(token_ids, list):
                token_id = token_ids[0] if len(token_ids) > 0 else 3
            else:
                token_id = token_ids
            return self.vocab[token_id % len(self.vocab)] + " "

    return MockTokenizer()


def main():
    print("=== æµ‹è¯•å¢å¼ºçš„å®¢æˆ·ç«¯UI ===\n")

    # 1. åˆ›å»ºæµ‹è¯•æ¨¡å‹
    print("1. åˆ›å»ºæµ‹è¯•æ¨¡å‹...")
    bottom_model, top_model = create_mock_models()
    tokenizer = create_mock_tokenizer()
    print("   âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆ\n")

    # 2. è¿æ¥åˆ°æœåŠ¡å™¨
    print("2. è¿æ¥åˆ°gRPCæœåŠ¡å™¨...")
    print("   æœåŠ¡å™¨åœ°å€: localhost:50051")
    try:
        client = GRPCComputeClient("localhost:50051")
        client.connect()
        print("   âœ“ è¿æ¥æˆåŠŸ\n")
    except Exception as e:
        print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
        print("\n   è¯·ç¡®ä¿æœåŠ¡ç«¯æ­£åœ¨è¿è¡Œ:")
        print("   python testcode/test_enhanced_monitoring.py")
        print("\n   æˆ–è€…ä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬:")
        print("   python examples/quickstart_server.py")
        return

    # 3. åˆ›å»ºå¢å¼ºçš„å®¢æˆ·ç«¯UI
    print("3. åˆ›å»ºå¢å¼ºçš„å®¢æˆ·ç«¯UI...")
    ui = ClientUI(
        client=client,
        bottom_model=bottom_model,
        top_model=top_model,
        tokenizer=tokenizer,
        theme="default"
    )
    print("   âœ“ UI åˆ›å»ºå®Œæˆ")
    print("   âœ“ ç›‘æ§ç®¡ç†å™¨å·²åˆå§‹åŒ–\n")

    # 4. å¯åŠ¨UI
    print("4. å¯åŠ¨å®¢æˆ·ç«¯UI...")
    print("\n" + "="*60)
    print("ğŸ“Š å®¢æˆ·ç«¯ç›‘æ§ UI åŒ…å« 3 ä¸ªæ ‡ç­¾é¡µ:")
    print("   1. ğŸ“ æ–‡æœ¬ç”Ÿæˆ - äº¤äº’å¼æ–‡æœ¬ç”Ÿæˆç•Œé¢")
    print("   2. ğŸ“ å®æ—¶æ—¥å¿— - å®¢æˆ·ç«¯æ“ä½œæ—¥å¿—")
    print("   3. â±ï¸ å»¶è¿Ÿåˆ†æ - æœåŠ¡å™¨é€šä¿¡å»¶è¿Ÿç»Ÿè®¡")
    print("="*60)
    print("\nğŸŒ UI å°†åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://127.0.0.1:7860")
    print("\nâš¡ åŠŸèƒ½ç‰¹æ€§:")
    print("   â€¢ å®æ—¶è®°å½•æ¯æ¬¡æœåŠ¡å™¨é€šä¿¡çš„å»¶è¿Ÿ")
    print("   â€¢ æ—¥å¿—çº§åˆ«è¿‡æ»¤ (DEBUG/INFO/WARNING/ERROR)")
    print("   â€¢ å»¶è¿Ÿç™¾åˆ†ä½ç»Ÿè®¡ (P50/P95/P99)")
    print("   â€¢ äº¤äº’å¼ Plotly å›¾è¡¨")
    print("   â€¢ æ¯ 2 ç§’è‡ªåŠ¨åˆ·æ–°ç›‘æ§æ•°æ®")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   â€¢ åœ¨'æ–‡æœ¬ç”Ÿæˆ'Tabç”Ÿæˆæ–‡æœ¬ï¼Œä¼šè‡ªåŠ¨è®°å½•å»¶è¿Ÿ")
    print("   â€¢ åˆ‡æ¢åˆ°'å®æ—¶æ—¥å¿—'TabæŸ¥çœ‹æ“ä½œæ—¥å¿—")
    print("   â€¢ åˆ‡æ¢åˆ°'å»¶è¿Ÿåˆ†æ'TabæŸ¥çœ‹é€šä¿¡æ€§èƒ½")
    print("\næŒ‰ Ctrl+C åœæ­¢\n")

    try:
        ui.launch(
            share=False,
            server_port=7860,
            inbrowser=True,
            blocking=True
        )
    except KeyboardInterrupt:
        print("\n\nâœ“ æµ‹è¯•å®Œæˆï¼")
    finally:
        try:
            client.disconnect()
            print("âœ“ å·²æ–­å¼€ä¸æœåŠ¡å™¨çš„è¿æ¥")
        except:
            pass


if __name__ == "__main__":
    main()
