#!/usr/bin/env python3
"""
gRPC å’Œ PyTorch å†²çªè¯Šæ–­è„šæœ¬

è¯Šæ–­åŒæ—¶ä½¿ç”¨ gRPC å’Œ PyTorch æ—¶å¯èƒ½å‡ºç°çš„é—®é¢˜ï¼š
- çº¿ç¨‹å†²çª
- mutex è­¦å‘Š
- åˆå§‹åŒ–é¡ºåºé—®é¢˜
- æ€§èƒ½é—®é¢˜
"""

import os
import sys
import time
import threading
import torch
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ grpc ä¹‹å‰ï¼‰
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'
os.environ.setdefault('OMP_NUM_THREADS', '1')
os.environ.setdefault('MKL_NUM_THREADS', '1')
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnComm', 'src'))

logging.basicConfig(level=logging.WARNING)

from splitlearn_comm import GRPCComputeServer
from splitlearn_comm.core import ComputeFunction


def print_separator(title=""):
    """æ‰“å°åˆ†éš”çº¿"""
    if title:
        print("\n" + "=" * 70)
        print(f"  {title}")
        print("=" * 70)
    else:
        print("\n" + "=" * 70)


def test_pytorch_alone():
    """æµ‹è¯• 1: å•ç‹¬ä½¿ç”¨ PyTorch"""
    print_separator("æµ‹è¯• 1: å•ç‹¬ä½¿ç”¨ PyTorch")
    
    print("\nâœ… æµ‹è¯• PyTorch å•ç‹¬ä½¿ç”¨...")
    
    try:
        # åˆ›å»ºå¼ é‡
        tensor = torch.randn(10, 10)
        print(f"  âœ“ åˆ›å»ºå¼ é‡: {tensor.shape}")
        
        # çŸ©é˜µä¹˜æ³•
        result = torch.matmul(tensor, tensor)
        print(f"  âœ“ çŸ©é˜µä¹˜æ³•: {result.shape}")
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = torch.nn.Linear(10, 5)
        output = model(tensor)
        print(f"  âœ“ æ¨¡å‹æ¨ç†: {output.shape}")
        
        print("\nâœ… PyTorch å•ç‹¬ä½¿ç”¨æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"\nâŒ PyTorch å•ç‹¬ä½¿ç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_grpc_alone():
    """æµ‹è¯• 2: å•ç‹¬ä½¿ç”¨ gRPCï¼ˆä¸ä½¿ç”¨ PyTorchï¼‰"""
    print_separator("æµ‹è¯• 2: å•ç‹¬ä½¿ç”¨ gRPCï¼ˆä¸ä½¿ç”¨ PyTorchï¼‰")
    
    print("\nâœ… æµ‹è¯• gRPC å•ç‹¬ä½¿ç”¨...")
    
    class SimpleCompute(ComputeFunction):
        def compute(self, input_tensor):
            # ä¸ä½¿ç”¨ PyTorchï¼Œåªåšç®€å•æ“ä½œ
            return input_tensor * 2
    
    try:
        compute_fn = SimpleCompute()
        server = GRPCComputeServer(
            compute_fn=compute_fn,
            host="0.0.0.0",
            port=50057,
            max_workers=1
        )
        
        print(f"  âœ“ æœåŠ¡å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è®¡ç®—å‡½æ•°
        test_input = torch.randn(5, 5)
        output = compute_fn.compute(test_input)
        print(f"  âœ“ è®¡ç®—å‡½æ•°æµ‹è¯•: {output.shape}")
        
        server.stop(grace=1)
        print(f"  âœ“ æœåŠ¡å™¨åœæ­¢æˆåŠŸ")
        
        print("\nâœ… gRPC å•ç‹¬ä½¿ç”¨æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"\nâŒ gRPC å•ç‹¬ä½¿ç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_grpc_with_pytorch():
    """æµ‹è¯• 3: gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨"""
    print_separator("æµ‹è¯• 3: gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨")
    
    print("\nâš ï¸  æµ‹è¯• gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨...")
    
    class PyTorchCompute(ComputeFunction):
        def __init__(self):
            self.model = torch.nn.Linear(10, 10)
            self.model.eval()
            self.request_count = 0
        
        def compute(self, input_tensor):
            self.request_count += 1
            with torch.no_grad():
                return self.model(input_tensor)
    
    try:
        compute_fn = PyTorchCompute()
        print(f"  âœ“ è®¡ç®—å‡½æ•°åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨ PyTorch æ¨¡å‹ï¼‰")
        
        server = GRPCComputeServer(
            compute_fn=compute_fn,
            host="0.0.0.0",
            port=50058,
            max_workers=1  # å•çº¿ç¨‹æ¨¡å¼
        )
        
        print(f"  âœ“ æœåŠ¡å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è®¡ç®—å‡½æ•°
        test_input = torch.randn(1, 10)
        print(f"  âœ“ æµ‹è¯•è¾“å…¥: {test_input.shape}")
        
        output = compute_fn.compute(test_input)
        print(f"  âœ“ è®¡ç®—æˆåŠŸ: {output.shape}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Š
        print(f"\n  âš ï¸  æ£€æŸ¥æ˜¯å¦æœ‰ mutex è­¦å‘Š...")
        print(f"     (å¦‚æœçœ‹åˆ° mutex è­¦å‘Šï¼Œè¯´æ˜æœ‰çº¿ç¨‹å†²çª)")
        
        server.stop(grace=1)
        print(f"  âœ“ æœåŠ¡å™¨åœæ­¢æˆåŠŸ")
        
        print(f"\nâœ… gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨æµ‹è¯•å®Œæˆ")
        print(f"   å¤„ç†äº† {compute_fn.request_count} ä¸ªè¯·æ±‚")
        return True
        
    except Exception as e:
        print(f"\nâŒ gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_threading_conflict():
    """æµ‹è¯• 4: çº¿ç¨‹å†²çªæ£€æµ‹"""
    print_separator("æµ‹è¯• 4: çº¿ç¨‹å†²çªæ£€æµ‹")
    
    print("\nğŸ” æ£€æŸ¥çº¿ç¨‹é…ç½®...")
    
    print(f"\nPyTorch çº¿ç¨‹é…ç½®:")
    print(f"  è®¡ç®—çº¿ç¨‹æ•°: {torch.get_num_threads()}")
    print(f"  äº’æ“ä½œçº¿ç¨‹æ•°: {torch.get_num_interop_threads()}")
    
    print(f"\nç¯å¢ƒå˜é‡:")
    print(f"  OMP_NUM_THREADS: {os.environ.get('OMP_NUM_THREADS', 'æœªè®¾ç½®')}")
    print(f"  MKL_NUM_THREADS: {os.environ.get('MKL_NUM_THREADS', 'æœªè®¾ç½®')}")
    print(f"  NUMEXPR_NUM_THREADS: {os.environ.get('NUMEXPR_NUM_THREADS', 'æœªè®¾ç½®')}")
    
    print(f"\nå½“å‰çº¿ç¨‹æ•°:")
    print(f"  æ´»åŠ¨çº¿ç¨‹æ•°: {threading.active_count()}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹å†²çª
    print(f"\nâš ï¸  æ½œåœ¨é—®é¢˜:")
    if torch.get_num_threads() > 1:
        print(f"  - PyTorch ä½¿ç”¨å¤šçº¿ç¨‹ ({torch.get_num_threads()} ä¸ªçº¿ç¨‹)")
        print(f"  - å¯èƒ½ä¸ gRPC çš„çº¿ç¨‹æ± å†²çª")
    else:
        print(f"  - PyTorch ä½¿ç”¨å•çº¿ç¨‹ âœ…")
    
    if threading.active_count() > 1:
        print(f"  - å½“å‰æœ‰ {threading.active_count()} ä¸ªæ´»åŠ¨çº¿ç¨‹")
        print(f"  - å¯èƒ½å­˜åœ¨çº¿ç¨‹ç«äº‰")


def test_initialization_order():
    """æµ‹è¯• 5: åˆå§‹åŒ–é¡ºåº"""
    print_separator("æµ‹è¯• 5: åˆå§‹åŒ–é¡ºåºé—®é¢˜")
    
    print("\nğŸ” æ£€æŸ¥åˆå§‹åŒ–é¡ºåº...")
    
    print(f"\nå½“å‰å¯¼å…¥é¡ºåº:")
    print(f"  1. torch (å·²å¯¼å…¥)")
    print(f"  2. grpc (é€šè¿‡ splitlearn_comm å¯¼å…¥)")
    
    print(f"\nâš ï¸  å¯èƒ½çš„é—®é¢˜:")
    print(f"  - å¦‚æœå…ˆå¯¼å…¥ torchï¼Œå†å¯¼å…¥ grpcï¼Œå¯èƒ½å¯¼è‡´çº¿ç¨‹å†²çª")
    print(f"  - å»ºè®®ï¼šå…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå†å¯¼å…¥ torchï¼Œæœ€åå¯¼å…¥ grpc")
    
    print(f"\nâœ… å»ºè®®çš„å¯¼å…¥é¡ºåº:")
    print(f"  1. è®¾ç½®ç¯å¢ƒå˜é‡ (OMP_NUM_THREADS=1 ç­‰)")
    print(f"  2. import torch")
    print(f"  3. torch.set_num_threads(1)")
    print(f"  4. import grpc / from splitlearn_comm import ...")


def diagnose_common_issues():
    """è¯Šæ–­å¸¸è§é—®é¢˜"""
    print_separator("å¸¸è§é—®é¢˜è¯Šæ–­")
    
    print("\nğŸ“‹ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ:")
    
    print("\n1. mutex è­¦å‘Š")
    print("   ç—‡çŠ¶: [mutex.cc : 452] RAW: Lock blocking")
    print("   åŸå› : PyTorch å’Œ gRPC çš„çº¿ç¨‹æ± å†²çª")
    print("   è§£å†³:")
    print("     - è®¾ç½® max_workers=1 (å•çº¿ç¨‹ gRPC)")
    print("     - è®¾ç½® torch.set_num_threads(1)")
    print("     - è®¾ç½®ç¯å¢ƒå˜é‡ OMP_NUM_THREADS=1")
    
    print("\n2. æ€§èƒ½ä¸‹é™")
    print("   ç—‡çŠ¶: åŒæ—¶ä½¿ç”¨æ—¶æ€§èƒ½æ˜æ˜¾ä¸‹é™")
    print("   åŸå› : çº¿ç¨‹ç«äº‰å¯¼è‡´ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€")
    print("   è§£å†³:")
    print("     - ä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼")
    print("     - ä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬ (AsyncGRPCComputeServer)")
    
    print("\n3. æ­»é”æˆ–å¡ä½")
    print("   ç—‡çŠ¶: ç¨‹åºå¡ä½ä¸å“åº”")
    print("   åŸå› : çº¿ç¨‹æ­»é”")
    print("   è§£å†³:")
    print("     - æ£€æŸ¥é”çš„ä½¿ç”¨")
    print("     - ä½¿ç”¨è¶…æ—¶æœºåˆ¶")
    print("     - é¿å…åœ¨è®¡ç®—å‡½æ•°ä¸­ä½¿ç”¨é”")
    
    print("\n4. å†…å­˜é—®é¢˜")
    print("   ç—‡çŠ¶: å†…å­˜æŒç»­å¢é•¿")
    print("   åŸå› : çº¿ç¨‹æ± ç¼“å­˜æˆ–æ¨¡å‹æœªé‡Šæ”¾")
    print("   è§£å†³:")
    print("     - ä½¿ç”¨ torch.no_grad()")
    print("     - åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¼ é‡")
    print("     - é™åˆ¶çº¿ç¨‹æ± å¤§å°")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 70)
    print("gRPC å’Œ PyTorch å†²çªè¯Šæ–­")
    print("=" * 70)
    
    results = {}
    
    # è¿è¡Œæµ‹è¯•
    results['pytorch_alone'] = test_pytorch_alone()
    results['grpc_alone'] = test_grpc_alone()
    results['grpc_with_pytorch'] = test_grpc_with_pytorch()
    
    # è¯Šæ–­
    test_threading_conflict()
    test_initialization_order()
    diagnose_common_issues()
    
    # æ€»ç»“
    print_separator("æµ‹è¯•æ€»ç»“")
    
    print("\næµ‹è¯•ç»“æœ:")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name:25s}: {status}")
    
    print("\nğŸ’¡ å»ºè®®:")
    if not results.get('grpc_with_pytorch', False):
        print("  - gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨æœ‰é—®é¢˜")
        print("  - å»ºè®®ä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼ (max_workers=1)")
        print("  - å»ºè®®è®¾ç½® torch.set_num_threads(1)")
        print("  - å»ºè®®ä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬ (AsyncGRPCComputeServer)")
    else:
        print("  - gRPC å’Œ PyTorch åŒæ—¶ä½¿ç”¨æ­£å¸¸")
        print("  - å¦‚æœä»æœ‰é—®é¢˜ï¼Œæ£€æŸ¥å…·ä½“é”™è¯¯ä¿¡æ¯")
    
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

