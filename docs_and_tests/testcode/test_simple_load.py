#!/usr/bin/env python3
"""
ç®€å•çš„æ¨¡å‹åŠ è½½æµ‹è¯• - ä½¿ç”¨ core åº“

åªæµ‹è¯•åŠ è½½ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œæ˜¾ç¤ºè¯¦ç»†è¿›åº¦
"""

# ============================================================================
# ç¬¬ä¸€æ­¥ï¼šåœ¨æœ€å¼€å§‹å¯¼å…¥ splitlearn_core.models.gpt2ï¼ˆæµ‹è¯•æ˜¯å¦å¡åœ¨è¿™é‡Œï¼‰
# ============================================================================
print("[0/10] ç¬¬ä¸€æ­¥ï¼šåœ¨æœ€å¼€å§‹å¯¼å…¥ splitlearn_core.models.gpt2...")
print("   è¿™æ­¥ç§»åˆ°æœ€å‰é¢ï¼Œä»¥ç¡®å®šæ˜¯å¦æ˜¯è¿™é‡Œå¯¼è‡´å¡ä½")

# å…ˆå¯¼å…¥å¿…è¦çš„æ ‡å‡†åº“ï¼ˆç”¨äºè·¯å¾„æ“ä½œï¼‰
import os
import sys

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
core_src_path = os.path.join(project_root, 'SplitLearnCore', 'src')
sys.path.insert(0, core_src_path)
print(f"   âœ“ è·¯å¾„å·²æ·»åŠ : {core_src_path}")

# åœ¨æœ€å¼€å§‹å°±å¯¼å…¥ï¼ˆæµ‹è¯•æ˜¯å¦å¡åœ¨è¿™é‡Œï¼‰
print("   â³ å¼€å§‹å¯¼å…¥ splitlearn_core.models.gpt2...")

# é€æ­¥å¯¼å…¥ï¼Œç¡®å®šå¡åœ¨å“ªä¸€æ­¥
print("      [6.1] å¯¼å…¥ splitlearn_core...")
print("      âš ï¸  æ³¨æ„ï¼šå¯¼å…¥ splitlearn_core ä¼šè§¦å‘ä¸€ç³»åˆ—å¯¼å…¥")
print("      âš ï¸  åŒ…æ‹¬ torchã€transformers ç­‰ï¼Œå¯èƒ½å¯¼è‡´ mutex è­¦å‘Š")
import splitlearn_core
print("      âœ“ splitlearn_core å¯¼å…¥æˆåŠŸ")

print("      [6.2] å¯¼å…¥ splitlearn_core.models...")
import splitlearn_core.models
print("      âœ“ splitlearn_core.models å¯¼å…¥æˆåŠŸ")

print("      [6.3] å¯¼å…¥ splitlearn_core.models.gpt2...")
import splitlearn_core.models.gpt2
print("      âœ“ splitlearn_core.models.gpt2 å¯¼å…¥æˆåŠŸ")

print("      [6.4] æ£€æŸ¥ gpt2 æ¨¡å—çš„å†…å®¹...")
print(f"      gpt2 æ¨¡å—: {splitlearn_core.models.gpt2}")
print(f"      gpt2 æ¨¡å—è·¯å¾„: {splitlearn_core.models.gpt2.__file__}")

print("      [6.5] å°è¯•å¯¼å…¥ GPT2TrunkModel...")
print("      â³ è¿™æ­¥å¯èƒ½ä¼šå¡ä½...")
from splitlearn_core.models.gpt2 import GPT2TrunkModel
print("   âœ“ GPT2TrunkModel å¯¼å…¥æˆåŠŸï¼")

# ============================================================================
# ç¬¬äºŒæ­¥ï¼šå¯¼å…¥å…¶ä»–åº“
# ============================================================================
print("\n[1/10] å¯¼å…¥å…¶ä»–æ ‡å‡†åº“...")
import time
print("   âœ“ time å¯¼å…¥æˆåŠŸ")

print("[2/10] è®¾ç½®ç¯å¢ƒå˜é‡...")
os.environ.setdefault('OMP_NUM_THREADS', '1')
print("   âœ“ OMP_NUM_THREADS è®¾ç½®")
os.environ.setdefault('MKL_NUM_THREADS', '1')
print("   âœ“ MKL_NUM_THREADS è®¾ç½®")
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')
print("   âœ“ NUMEXPR_NUM_THREADS è®¾ç½®")

print("[3/10] å¯¼å…¥ torch...")
import torch
print("   âœ“ torch å¯¼å…¥æˆåŠŸ")
print(f"   âœ“ torch ç‰ˆæœ¬: {torch.__version__}")

print("[4/10] å¯¼å…¥ transformers...")
from transformers import GPT2Config
print("   âœ“ GPT2Config å¯¼å…¥æˆåŠŸ")

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    return f"{size_bytes / (1024*1024):.2f} MB"

def main():
    print("\n" + "=" * 70)
    print("ğŸ§ª ç®€å•æ¨¡å‹åŠ è½½æµ‹è¯•ï¼ˆä½¿ç”¨ core åº“ï¼‰")
    print("=" * 70)
    
    # æµ‹è¯•æ–‡ä»¶
    model_path = os.path.join(current_dir, "gpt2_trunk_full.pt")
    
    # 1. æ£€æŸ¥æ–‡ä»¶
    print(f"\nğŸ“ æ£€æŸ¥æ–‡ä»¶: {os.path.basename(model_path)}")
    if not os.path.exists(model_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return 1
    
    file_size = os.path.getsize(model_path)
    print(f"   âœ“ æ–‡ä»¶å­˜åœ¨")
    print(f"   âœ“ æ–‡ä»¶å¤§å°: {format_size(file_size)}")
    
    # 2. æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨ torch.load()
    print(f"\n" + "-" * 70)
    print("æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨ torch.load()")
    print("-" * 70)
    
    print(f"\nâ³ å¼€å§‹åŠ è½½ï¼ˆtorch.loadï¼‰...")
    print(f"   è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    start_time = time.time()
    try:
        model = torch.load(model_path, map_location='cpu', weights_only=False)
        load_time = time.time() - start_time
        
        print(f"\n   âœ“ åŠ è½½æˆåŠŸï¼")
        print(f"   âœ“ è€—æ—¶: {load_time:.2f} ç§’")
        print(f"   âœ“ æ¨¡å‹ç±»å‹: {type(model).__name__}")
        
        # æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   âœ“ å‚æ•°é‡: {total_params:,}")
        print(f"   âœ“ æ¨¡å‹å¤§å°: {format_size(total_params * 4)}")
        
        # æµ‹è¯•æ¨ç†
        print(f"\nğŸ§ª æµ‹è¯•æ¨ç†...")
        model.eval()
        test_input = torch.randn(1, 5, 768)
        with torch.no_grad():
            output = model(test_input)
        print(f"   âœ“ æ¨ç†æˆåŠŸ")
        print(f"   è¾“å…¥: {test_input.shape} -> è¾“å‡º: {output.shape}")
        
        method1_success = True
        
    except Exception as e:
        print(f"\n   âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        method1_success = False
    
    # 3. æ–¹æ³• 2: ä½¿ç”¨ core åº“åˆ›å»ºæ¨¡å‹å®ä¾‹
    print(f"\n" + "-" * 70)
    print("æ–¹æ³• 2: ä½¿ç”¨ SplitLearnCore æ¨¡å‹ç±»")
    print("-" * 70)
    
    print(f"\nâ³ åˆ›å»ºæ¨¡å‹å®ä¾‹...")
    try:
        config = GPT2Config()
        model_instance = GPT2TrunkModel(
            config=config,
            start_layer=2,
            end_layer=10
        )
        print(f"   âœ“ æ¨¡å‹å®ä¾‹åˆ›å»ºæˆåŠŸ")
        print(f"   âœ“ ç±»å‹: {type(model_instance).__name__}")
        
        # å°è¯•åŠ è½½ state_dictï¼ˆå¦‚æœæ–‡ä»¶åŒ…å« state_dictï¼‰
        print(f"\nâ³ å°è¯•åŠ è½½ state_dict...")
        loaded_data = torch.load(model_path, map_location='cpu', weights_only=False)
        
        if isinstance(loaded_data, dict):
            print(f"   âœ“ æ–‡ä»¶åŒ…å« state_dict")
            model_instance.load_state_dict(loaded_data, strict=False)
            print(f"   âœ“ state_dict åŠ è½½æˆåŠŸ")
        else:
            print(f"   âš ï¸  æ–‡ä»¶åŒ…å«å®Œæ•´æ¨¡å‹å¯¹è±¡ï¼Œä¸æ˜¯ state_dict")
            print(f"   ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸º prepare_models.py ä¿å­˜çš„æ˜¯å®Œæ•´æ¨¡å‹ï¼‰")
        
        method2_success = True
        
    except Exception as e:
        print(f"\n   âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        method2_success = False
    
    # æ€»ç»“
    print(f"\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    print(f"   æ–¹æ³• 1 (torch.load): {'âœ… æˆåŠŸ' if method1_success else 'âŒ å¤±è´¥'}")
    print(f"   æ–¹æ³• 2 (core åº“): {'âœ… æˆåŠŸ' if method2_success else 'âŒ å¤±è´¥'}")
    
    return 0 if (method1_success or method2_success) else 1

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

