#!/usr/bin/env python3
"""
gRPC å®¢æˆ·ç«¯æµ‹è¯•è„šæœ¬ - æ˜¾ç¤ºæ•°æ®ä¼ è¾“è¯¦æƒ…

åœ¨ç»ˆç«¯è¿è¡Œæ­¤è„šæœ¬è¿æ¥æœåŠ¡å™¨ï¼Œå¯ä»¥çœ‹åˆ°ï¼š
- å‘é€çš„è¯·æ±‚æ•°æ®
- æ¥æ”¶çš„å“åº”æ•°æ®
- æ•°æ®ä¼ è¾“çš„è¯¦ç»†ä¿¡æ¯
"""

import os
import sys
import time
import torch
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ grpc ä¹‹å‰ï¼‰
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'
os.environ.setdefault('OMP_NUM_THREADS', '1')
os.environ.setdefault('MKL_NUM_THREADS', '1')
os.environ.setdefault('NUMEXPR_NUM_THREADS', '1')

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnComm', 'src'))

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)

from splitlearn_comm import GRPCComputeClient

# æµ‹è¯•é…ç½®
SERVER_ADDRESS = "localhost:50055"
TIMEOUT = 30.0


def print_tensor_info(tensor, name, prefix="   "):
    """æ‰“å°å¼ é‡è¯¦ç»†ä¿¡æ¯"""
    print(f"{prefix}å½¢çŠ¶: {tensor.shape}")
    print(f"{prefix}æ•°æ®ç±»å‹: {tensor.dtype}")
    print(f"{prefix}æ•°æ®å¤§å°: {tensor.numel() * 4 / 1024:.2f} KB")
    print(f"{prefix}è®¾å¤‡: {tensor.device}")
    print(f"{prefix}æœ€å°å€¼: {tensor.min().item():.6f}")
    print(f"{prefix}æœ€å¤§å€¼: {tensor.max().item():.6f}")
    print(f"{prefix}å¹³å‡å€¼: {tensor.mean().item():.6f}")
    print(f"{prefix}æ ‡å‡†å·®: {tensor.std().item():.6f}")
    flat = tensor.flatten()
    print(f"{prefix}å‰10ä¸ªå€¼: {flat[:10].tolist()}")


def test_connection():
    """æµ‹è¯•è¿æ¥"""
    print("\n" + "=" * 70)
    print("ğŸ”Œ è¿æ¥æµ‹è¯•")
    print("=" * 70)
    
    client = GRPCComputeClient(
        server_address=SERVER_ADDRESS,
        timeout=TIMEOUT
    )
    
    print(f"\nğŸ“¡ è¿æ¥æœåŠ¡å™¨: {SERVER_ADDRESS}")
    print("   æ­£åœ¨è¿æ¥...")
    
    if client.connect():
        print("   âœ“ è¿æ¥æˆåŠŸï¼")
        return client
    else:
        print("   âŒ è¿æ¥å¤±è´¥ï¼")
        print(f"\nğŸ’¡ è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ:")
        print(f"   python testcode/server_comm_test.py")
        return None


def test_compute(client, request_num=1):
    """æµ‹è¯•è®¡ç®—å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"""
    print("\n" + "=" * 70)
    print(f"ğŸ“¤ å‘é€è¯·æ±‚ #{request_num}")
    print("=" * 70)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.randn(1, 10, 768)
    
    print(f"\nğŸ“Š å‡†å¤‡å‘é€çš„æ•°æ®:")
    print_tensor_info(test_input, "è¾“å…¥æ•°æ®")
    
    # è®¡ç®—æ•°æ®å¤§å°
    input_size_kb = test_input.numel() * 4 / 1024
    
    # å‘é€è¯·æ±‚
    print(f"\nğŸš€ å‘é€è®¡ç®—è¯·æ±‚...")
    print(f"   æ•°æ®å¤§å°: {input_size_kb:.2f} KB")
    print(f"   æ­£åœ¨ä¼ è¾“...")
    
    start_time = time.time()
    
    try:
        output = client.compute(test_input)
        
        total_time = (time.time() - start_time) * 1000
        
        print(f"\nğŸ“¥ æ”¶åˆ°å“åº”")
        print("=" * 70)
        
        # æ˜¾ç¤ºè¾“å‡ºæ•°æ®ä¿¡æ¯
        print(f"\nğŸ“Š æ¥æ”¶åˆ°çš„æ•°æ®:")
        print_tensor_info(output, "è¾“å‡ºæ•°æ®")
        
        # è®¡ç®—ä¼ è¾“ç»Ÿè®¡
        output_size_kb = output.numel() * 4 / 1024
        total_size_kb = input_size_kb + output_size_kb
        
        print(f"\nğŸ“¡ ä¼ è¾“ç»Ÿè®¡:")
        print(f"   å‘é€æ•°æ®: {input_size_kb:.2f} KB")
        print(f"   æ¥æ”¶æ•°æ®: {output_size_kb:.2f} KB")
        print(f"   æ€»ä¼ è¾“: {total_size_kb:.2f} KB")
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
        print(f"   ååé‡: {total_size_kb / (total_time / 1000):.2f} KB/s")
        
        # éªŒè¯ç»“æœ
        if output.shape == test_input.shape:
            print(f"\nâœ… è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {output.shape}")
        else:
            print(f"\nâš ï¸  è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸ: {output.shape} (æœŸæœ›: {test_input.shape})")
        
        print("=" * 70)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ è¯·æ±‚å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multiple_requests(client, num_requests=3):
    """æµ‹è¯•å¤šæ¬¡è¯·æ±‚"""
    print("\n" + "=" * 70)
    print(f"ğŸ”„ å¤šæ¬¡è¯·æ±‚æµ‹è¯• ({num_requests} æ¬¡)")
    print("=" * 70)
    
    successes = 0
    total_time = 0.0
    total_data = 0.0
    
    for i in range(num_requests):
        print(f"\n--- è¯·æ±‚ {i+1}/{num_requests} ---")
        
        test_input = torch.randn(1, 5, 768)
        input_size_kb = test_input.numel() * 4 / 1024
        
        start_time = time.time()
        try:
            output = client.compute(test_input)
            elapsed = (time.time() - start_time) * 1000
            
            output_size_kb = output.numel() * 4 / 1024
            request_data = input_size_kb + output_size_kb
            
            total_time += elapsed
            total_data += request_data
            successes += 1
            
            print(f"   âœ“ æˆåŠŸ (è€—æ—¶: {elapsed:.2f} ms, æ•°æ®: {request_data:.2f} KB)")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   æˆåŠŸ: {successes}/{num_requests}")
    print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
    print(f"   å¹³å‡è€—æ—¶: {total_time/successes:.2f} ms" if successes > 0 else "   N/A")
    print(f"   æ€»ä¼ è¾“: {total_data:.2f} KB")
    print(f"   å¹³å‡ååé‡: {total_data / (total_time / 1000):.2f} KB/s" if total_time > 0 else "   N/A")
    
    return successes == num_requests


def test_service_info(client):
    """æµ‹è¯•æœåŠ¡ä¿¡æ¯"""
    print("\n" + "=" * 70)
    print("â„¹ï¸  æœåŠ¡ä¿¡æ¯æŸ¥è¯¢")
    print("=" * 70)
    
    try:
        info = client.get_service_info()
        
        print(f"\nğŸ“‹ æœåŠ¡å™¨ä¿¡æ¯:")
        print(f"   æœåŠ¡å: {info.get('service_name', 'N/A')}")
        print(f"   ç‰ˆæœ¬: {info.get('version', 'N/A')}")
        print(f"   è®¾å¤‡: {info.get('device', 'N/A')}")
        print(f"   æ€»è¯·æ±‚æ•°: {info.get('total_requests', 0)}")
        print(f"   è¿è¡Œæ—¶é—´: {info.get('uptime_seconds', 0):.1f} ç§’")
        
        return True
        
    except Exception as e:
        print(f"   âŒ è·å–æœåŠ¡ä¿¡æ¯å¤±è´¥: {e}")
        return False


def main():
    print("\n" + "=" * 70)
    print("ğŸ’» gRPC å®¢æˆ·ç«¯æµ‹è¯•")
    print("=" * 70)
    print(f"\nğŸ“¡ æœåŠ¡å™¨åœ°å€: {SERVER_ADDRESS}")
    print(f"â±ï¸  è¶…æ—¶æ—¶é—´: {TIMEOUT} ç§’")
    print()
    
    # è¿æ¥æœåŠ¡å™¨
    client = test_connection()
    if client is None:
        return 1
    
    try:
        # æµ‹è¯•æœåŠ¡ä¿¡æ¯
        test_service_info(client)
        
        # æµ‹è¯•å•æ¬¡è®¡ç®—
        test_compute(client, request_num=1)
        
        # æµ‹è¯•å¤šæ¬¡è¯·æ±‚
        test_multiple_requests(client, num_requests=3)
        
        # å†æ¬¡æµ‹è¯•å•æ¬¡è®¡ç®—
        test_compute(client, request_num=2)
        
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å®¢æˆ·ç«¯ç»Ÿè®¡:")
        stats = client.get_statistics()
        print(f"   æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
        print(f"   æˆåŠŸè¯·æ±‚: {stats.get('successful_requests', 0)}")
        print(f"   å¤±è´¥è¯·æ±‚: {stats.get('failed_requests', 0)}")
        print(f"   å¹³å‡ç½‘ç»œæ—¶é—´: {stats.get('avg_network_time_ms', 0):.2f} ms")
        print(f"   å¹³å‡è®¡ç®—æ—¶é—´: {stats.get('avg_compute_time_ms', 0):.2f} ms")
        
    finally:
        print("\nğŸ”Œ å…³é—­è¿æ¥...")
        client.close()
        print("   âœ“ è¿æ¥å·²å…³é—­")
    
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

