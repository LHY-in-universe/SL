#!/usr/bin/env python3
"""
gRPC å®¢æˆ·ç«¯æµ‹è¯•è„šæœ¬ - ç®€å•ç‰ˆæœ¬

è¿æ¥ç®€å•æœåŠ¡å™¨ï¼ˆä¸ä½¿ç”¨æ¨¡å‹ï¼‰ï¼Œæµ‹è¯•é€šä¿¡åŠŸèƒ½
"""

import os
import sys
import time
import torch
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ grpc ä¹‹å‰ï¼‰
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearnComm', 'src'))

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)

from splitlearn_comm import GRPCComputeClient

# æµ‹è¯•é…ç½®
SERVER_ADDRESS = "localhost:50056"  # ç®€å•æœåŠ¡å™¨ç«¯å£
TIMEOUT = 30.0


def print_tensor_info(tensor, name, prefix="   "):
    """æ‰“å°å¼ é‡è¯¦ç»†ä¿¡æ¯"""
    print(f"{prefix}å½¢çŠ¶: {tensor.shape}")
    print(f"{prefix}æ•°æ®ç±»å‹: {tensor.dtype}")
    print(f"{prefix}æ•°æ®å¤§å°: {tensor.numel() * 4 / 1024:.2f} KB")
    print(f"{prefix}æœ€å°å€¼: {tensor.min().item():.6f}")
    print(f"{prefix}æœ€å¤§å€¼: {tensor.max().item():.6f}")
    print(f"{prefix}å¹³å‡å€¼: {tensor.mean().item():.6f}")


def test_connection():
    """æµ‹è¯•è¿æ¥"""
    print("\n" + "=" * 70)
    print("ğŸ”Œ è¿æ¥æµ‹è¯•")
    print("=" * 70)
    
    client = GRPCComputeClient(
        server_address=SERVER_ADDRESS,
        timeout=TIMEOUT
    )
    
    print(f"\nğŸ“¡ è¿æ¥æœåŠ¡å™¨: {SERVER_ADDRESS}")
    print("   æ­£åœ¨è¿æ¥...")
    
    if client.connect():
        print("   âœ“ è¿æ¥æˆåŠŸï¼")
        return client
    else:
        print("   âŒ è¿æ¥å¤±è´¥ï¼")
        print(f"\nğŸ’¡ è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ:")
        print(f"   python testcode/server_comm_simple.py")
        return None


def test_compute(client, request_num=1):
    """æµ‹è¯•è®¡ç®—å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"""
    print("\n" + "=" * 70)
    print(f"ğŸ“¤ å‘é€è¯·æ±‚ #{request_num}")
    print("=" * 70)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = torch.randn(1, 10, 768)
    
    print(f"\nğŸ“Š å‡†å¤‡å‘é€çš„æ•°æ®:")
    print_tensor_info(test_input, "è¾“å…¥æ•°æ®")
    
    # è®¡ç®—æ•°æ®å¤§å°
    input_size_kb = test_input.numel() * 4 / 1024
    
    # å‘é€è¯·æ±‚
    print(f"\nğŸš€ å‘é€è®¡ç®—è¯·æ±‚...")
    print(f"   æ•°æ®å¤§å°: {input_size_kb:.2f} KB")
    print(f"   æ­£åœ¨ä¼ è¾“...")
    
    start_time = time.time()
    
    try:
        output = client.compute(test_input)
        
        total_time = (time.time() - start_time) * 1000
        
        print(f"\nğŸ“¥ æ”¶åˆ°å“åº”")
        print("=" * 70)
        
        # æ˜¾ç¤ºè¾“å‡ºæ•°æ®ä¿¡æ¯
        print(f"\nğŸ“Š æ¥æ”¶åˆ°çš„æ•°æ®:")
        print_tensor_info(output, "è¾“å‡ºæ•°æ®")
        
        # éªŒè¯è®¡ç®—ç»“æœï¼ˆåº”è¯¥æ˜¯ input * 2 + 1ï¼‰
        expected = test_input * 2 + 1
        if torch.allclose(output, expected, atol=1e-5):
            print(f"\nâœ… è®¡ç®—ç»“æœæ­£ç¡®: output = input * 2 + 1")
        else:
            print(f"\nâš ï¸  è®¡ç®—ç»“æœä¸ç¬¦åˆé¢„æœŸ")
        
        # è®¡ç®—ä¼ è¾“ç»Ÿè®¡
        output_size_kb = output.numel() * 4 / 1024
        total_size_kb = input_size_kb + output_size_kb
        
        print(f"\nğŸ“¡ ä¼ è¾“ç»Ÿè®¡:")
        print(f"   å‘é€æ•°æ®: {input_size_kb:.2f} KB")
        print(f"   æ¥æ”¶æ•°æ®: {output_size_kb:.2f} KB")
        print(f"   æ€»ä¼ è¾“: {total_size_kb:.2f} KB")
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
        if total_time > 0:
            print(f"   ååé‡: {total_size_kb / (total_time / 1000):.2f} KB/s")
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        if output.shape == test_input.shape:
            print(f"\nâœ… è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {output.shape}")
        else:
            print(f"\nâš ï¸  è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸ: {output.shape} (æœŸæœ›: {test_input.shape})")
        
        print("=" * 70)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ è¯·æ±‚å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multiple_requests(client, num_requests=5):
    """æµ‹è¯•å¤šæ¬¡è¯·æ±‚"""
    print("\n" + "=" * 70)
    print(f"ğŸ”„ å¤šæ¬¡è¯·æ±‚æµ‹è¯• ({num_requests} æ¬¡)")
    print("=" * 70)
    
    successes = 0
    total_time = 0.0
    total_data = 0.0
    
    for i in range(num_requests):
        print(f"\n--- è¯·æ±‚ {i+1}/{num_requests} ---")
        
        test_input = torch.randn(1, 5, 768)
        input_size_kb = test_input.numel() * 4 / 1024
        
        start_time = time.time()
        try:
            output = client.compute(test_input)
            elapsed = (time.time() - start_time) * 1000
            
            # éªŒè¯ç»“æœ
            expected = test_input * 2 + 1
            if torch.allclose(output, expected, atol=1e-5):
                output_size_kb = output.numel() * 4 / 1024
                request_data = input_size_kb + output_size_kb
                
                total_time += elapsed
                total_data += request_data
                successes += 1
                
                print(f"   âœ“ æˆåŠŸ (è€—æ—¶: {elapsed:.2f} ms, æ•°æ®: {request_data:.2f} KB)")
            else:
                print(f"   âš ï¸  ç»“æœä¸æ­£ç¡®")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
    
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   æˆåŠŸ: {successes}/{num_requests}")
    if successes > 0:
        print(f"   æ€»è€—æ—¶: {total_time:.2f} ms")
        print(f"   å¹³å‡è€—æ—¶: {total_time/successes:.2f} ms")
        print(f"   æ€»ä¼ è¾“: {total_data:.2f} KB")
        if total_time > 0:
            print(f"   å¹³å‡ååé‡: {total_data / (total_time / 1000):.2f} KB/s")
    
    return successes == num_requests


def main():
    print("\n" + "=" * 70)
    print("ğŸ’» gRPC å®¢æˆ·ç«¯æµ‹è¯•ï¼ˆç®€å•ç‰ˆæœ¬ - æµ‹è¯•é€šä¿¡åŠŸèƒ½ï¼‰")
    print("=" * 70)
    print(f"\nğŸ“¡ æœåŠ¡å™¨åœ°å€: {SERVER_ADDRESS}")
    print(f"â±ï¸  è¶…æ—¶æ—¶é—´: {TIMEOUT} ç§’")
    print(f"ğŸ’¡ æœåŠ¡å™¨æ‰§è¡Œ: output = input * 2 + 1")
    print()
    
    # è¿æ¥æœåŠ¡å™¨
    client = test_connection()
    if client is None:
        return 1
    
    try:
        # æµ‹è¯•å•æ¬¡è®¡ç®—
        test_compute(client, request_num=1)
        
        # æµ‹è¯•å¤šæ¬¡è¯·æ±‚
        test_multiple_requests(client, num_requests=5)
        
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 70)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å®¢æˆ·ç«¯ç»Ÿè®¡:")
        stats = client.get_statistics()
        print(f"   æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
        print(f"   æˆåŠŸè¯·æ±‚: {stats.get('successful_requests', 0)}")
        print(f"   å¤±è´¥è¯·æ±‚: {stats.get('failed_requests', 0)}")
        print(f"   å¹³å‡ç½‘ç»œæ—¶é—´: {stats.get('avg_network_time_ms', 0):.2f} ms")
        print(f"   å¹³å‡è®¡ç®—æ—¶é—´: {stats.get('avg_compute_time_ms', 0):.2f} ms")
        
    finally:
        print("\nğŸ”Œ å…³é—­è¿æ¥...")
        client.close()
        print("   âœ“ è¿æ¥å·²å…³é—­")
    
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

