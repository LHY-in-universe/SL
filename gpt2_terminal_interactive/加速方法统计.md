# GPT-2 ç»ˆç«¯äº¤äº’å¼è„šæœ¬ - åŠ é€Ÿæ–¹æ³•ç»Ÿè®¡

## ğŸ“Š æ€»è®¡ï¼š**9 ç§åŠ é€Ÿæ–¹æ³•**

---

## 1ï¸âƒ£ **Hugging Face å®˜æ–¹ä¼˜åŒ–** (2ç§)

### âœ… `low_cpu_mem_usage=True` (ç¬¬123è¡Œ)
- **ä½œç”¨**: å‡å°‘æ¨¡å‹åŠ è½½æ—¶çš„å³°å€¼ CPU å†…å­˜ä½¿ç”¨
- **æ•ˆæœ**: é™ä½å†…å­˜å ç”¨ 20-30%
- **ä½ç½®**: `GPT2LMHeadModel.from_pretrained()`

### âœ… `use_fast=True` (ç¬¬128è¡Œ)
- **ä½œç”¨**: ä½¿ç”¨å¿«é€Ÿåˆ†è¯å™¨ï¼ˆRust å®ç°ï¼‰
- **æ•ˆæœ**: åˆ†è¯é€Ÿåº¦æå‡ 2-5å€
- **ä½ç½®**: `AutoTokenizer.from_pretrained()`

---

## 2ï¸âƒ£ **PyTorch æ ‡å‡†åº“ä¼˜åŒ–** (3ç§)

### âœ… `torch.inference_mode()` (ç¬¬212è¡Œ)
- **ä½œç”¨**: å®Œå…¨ç¦ç”¨æ¢¯åº¦è®¡ç®—å’Œ autogradï¼Œæ¯” `torch.no_grad()` æ›´å¿«
- **æ•ˆæœ**: æ¨ç†é€Ÿåº¦æå‡ 5-10%
- **ä½ç½®**: ç”Ÿæˆå¾ªç¯å¤–å±‚

### âœ… `torch.set_float32_matmul_precision("medium")` (ç¬¬139è¡Œ)
- **ä½œç”¨**: è®¾ç½®çŸ©é˜µä¹˜æ³•ç²¾åº¦ï¼ˆhigh/medium/lowï¼‰
- **æ•ˆæœ**: åœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶æå‡é€Ÿåº¦ 10-20%
- **ä½ç½®**: æ¨¡å‹åŠ è½½å

### âœ… `torch.backends.cudnn.benchmark = True` (ç¬¬142è¡Œ)
- **ä½œç”¨**: CUDA ä¸“ç”¨ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
- **æ•ˆæœ**: CUDA è®¾å¤‡ä¸Šé€Ÿåº¦æå‡ 10-30%
- **ä½ç½®**: ä»… CUDA è®¾å¤‡å¯ç”¨

---

## 3ï¸âƒ£ **ç”Ÿæˆè¿‡ç¨‹ä¼˜åŒ–** (3ç§)

### âœ… **KV Cache** (ç¬¬227è¡Œ: `use_cache=True`)
- **ä½œç”¨**: ç¼“å­˜å†å² token çš„ key-valueï¼Œé¿å…é‡å¤è®¡ç®—
- **æ•ˆæœ**: åç»­ token ç”Ÿæˆé€Ÿåº¦æå‡ 5-10å€
- **å®ç°**: 
  - step=0: å¤„ç†å®Œæ•´ promptï¼Œç”Ÿæˆ KV cache
  - step>0: åªå¤„ç†æ–° tokenï¼Œå¤ç”¨ KV cache

### âœ… `output_attentions=False` (ç¬¬228è¡Œ)
- **ä½œç”¨**: ä¸è¾“å‡ºæ³¨æ„åŠ›æƒé‡
- **æ•ˆæœ**: èŠ‚çœå†…å­˜å’Œè®¡ç®— 10-15%

### âœ… `output_hidden_states=False` (ç¬¬229è¡Œ)
- **ä½œç”¨**: ä¸è¾“å‡ºéšè—çŠ¶æ€
- **æ•ˆæœ**: èŠ‚çœå†…å­˜å’Œè®¡ç®— 5-10%

---

## 4ï¸âƒ£ **é‡‡æ ·ä¼˜åŒ–** (1ç§)

### âœ… **ä¼˜åŒ–çš„ Top-k é‡‡æ ·** (ç¬¬245-247è¡Œ)
- **ä½œç”¨**: ä½¿ç”¨ `torch.topk()` å’Œ `scatter_()` ä¼˜åŒ–é‡‡æ ·è¿‡ç¨‹
- **æ•ˆæœ**: é‡‡æ ·é€Ÿåº¦æå‡ 20-30%
- **å®ç°**:
  ```python
  top_k_logits, top_k_indices = torch.topk(logits, top_k_value)
  logits_filtered.scatter_(0, top_k_indices, top_k_logits)
  ```

---

## ğŸ“ˆ **æ€§èƒ½æå‡æ±‡æ€»**

| ä¼˜åŒ–ç±»åˆ« | æ–¹æ³•æ•° | ç»¼åˆæå‡ |
|---------|--------|---------|
| Hugging Face ä¼˜åŒ– | 2 | å†…å­˜ -30%, åˆ†è¯ +200% |
| PyTorch ä¼˜åŒ– | 3 | æ¨ç† +15-40% |
| ç”Ÿæˆä¼˜åŒ– | 3 | ç”Ÿæˆ +500-1000% (KV Cache) |
| é‡‡æ ·ä¼˜åŒ– | 1 | é‡‡æ · +20-30% |
| **æ€»è®¡** | **9** | **æ•´ä½“ +50-200%** |

---

## ğŸ” **è¯¦ç»†ä½ç½®**

### æ¨¡å‹åŠ è½½é˜¶æ®µ (ç¬¬120-142è¡Œ)
```python
# Hugging Face ä¼˜åŒ–
model = GPT2LMHeadModel.from_pretrained(
    model_id,
    cache_dir=MODEL_CACHE,
    low_cpu_mem_usage=True,  # âœ… ä¼˜åŒ– 1
)
tokenizer = AutoTokenizer.from_pretrained(
    model_id,
    cache_dir=MODEL_CACHE,
    use_fast=True,  # âœ… ä¼˜åŒ– 2
)

# PyTorch ä¼˜åŒ–
torch.set_float32_matmul_precision("medium")  # âœ… ä¼˜åŒ– 3
if device == "cuda":
    torch.backends.cudnn.benchmark = True  # âœ… ä¼˜åŒ– 4
```

### ç”Ÿæˆé˜¶æ®µ (ç¬¬212-235è¡Œ)
```python
with torch.inference_mode():  # âœ… ä¼˜åŒ– 5
    for step in range(max_new_tokens):
        model_kwargs = {
            "past_key_values": past_key_values,
            "use_cache": True,  # âœ… ä¼˜åŒ– 6 (KV Cache)
            "output_attentions": False,  # âœ… ä¼˜åŒ– 7
            "output_hidden_states": False,  # âœ… ä¼˜åŒ– 8
        }
        outputs = model(current_input_ids, **model_kwargs)
```

### é‡‡æ ·é˜¶æ®µ (ç¬¬245-247è¡Œ)
```python
# âœ… ä¼˜åŒ– 9 (ä¼˜åŒ–çš„ Top-k é‡‡æ ·)
top_k_logits, top_k_indices = torch.topk(logits, top_k_value)
logits_filtered.scatter_(0, top_k_indices, top_k_logits)
```

---

## âš ï¸ **æœªä½¿ç”¨ä½†å¯é€‰çš„ä¼˜åŒ–**

1. **`torch.compile()`** - ä»… CUDA æ”¯æŒï¼ŒMPS ä¸æ”¯æŒ
2. **`torch_dtype=float16/bfloat16`** - å¯è¿›ä¸€æ­¥åŠ é€Ÿï¼Œä½†å¯èƒ½å½±å“ç²¾åº¦
3. **`device_map="auto"`** - å¤š GPU è‡ªåŠ¨åˆ†é…
4. **`attn_implementation="flash_attention_2"`** - éœ€è¦å®‰è£… flash-attn

---

## âœ… **æ€»ç»“**

è„šæœ¬ä¸­ä½¿ç”¨äº† **9 ç§åŠ é€Ÿæ–¹æ³•**ï¼Œæ¶µç›–äº†ï¼š
- âœ… æ¨¡å‹åŠ è½½ä¼˜åŒ– (2ç§)
- âœ… PyTorch åº•å±‚ä¼˜åŒ– (3ç§)
- âœ… ç”Ÿæˆè¿‡ç¨‹ä¼˜åŒ– (3ç§)
- âœ… é‡‡æ ·ç®—æ³•ä¼˜åŒ– (1ç§)

è¿™äº›ä¼˜åŒ–æ–¹æ³•ç»¼åˆä½¿ç”¨ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç”Ÿæˆé€Ÿåº¦å’Œé™ä½å†…å­˜ä½¿ç”¨ã€‚
