"""
æµ‹è¯•é›†æˆåˆ° splitlearn-comm çš„å®¢æˆ·ç«¯ UI åŠŸèƒ½
"""
import sys
import os

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(project_root, 'SplitLearning', 'src'))
sys.path.insert(0, os.path.join(project_root, 'splitlearn-comm', 'src'))

import torch
from transformers import AutoTokenizer
from splitlearn_comm import GRPCComputeClient

def main():
    print("=" * 70)
    print("æµ‹è¯•é›†æˆçš„å®¢æˆ·ç«¯ UI (splitlearn-comm)")
    print("=" * 70)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    bottom_path = os.path.join(current_dir, "gpt2_bottom_cached.pt")
    top_path = os.path.join(current_dir, "gpt2_top_cached.pt")

    if not os.path.exists(bottom_path) or not os.path.exists(top_path):
        print("\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        print(f"   Bottom: {bottom_path}")
        print(f"   Top: {top_path}")
        print("\nè¯·è¿è¡Œ: python testcode/prepare_models.py")
        return 1

    print("\nâœ“ æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
    print(f"  Bottom: {os.path.getsize(bottom_path) / (1024**2):.1f} MB")
    print(f"  Top: {os.path.getsize(top_path) / (1024**2):.1f} MB")

    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    bottom_model = torch.load(bottom_path, map_location='cpu', weights_only=False)
    top_model = torch.load(top_path, map_location='cpu', weights_only=False)
    tokenizer = AutoTokenizer.from_pretrained('gpt2')
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

    # è¿æ¥æœåŠ¡å™¨
    print("\nè¿æ¥æœåŠ¡å™¨ (localhost:50053)...")
    client = GRPCComputeClient("localhost:50053", timeout=10.0)

    if not client.connect():
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼")
        print("\nè¯·å…ˆå¯åŠ¨æœåŠ¡å™¨:")
        print("  python testcode/start_server.py")
        return 1

    print("âœ“ å·²è¿æ¥åˆ°æœåŠ¡å™¨")

    # è·å–å®¢æˆ·ç«¯ç»Ÿè®¡
    stats = client.get_statistics()
    print(f"\nå®¢æˆ·ç«¯ç»Ÿè®¡:")
    print(f"  æ€»è¯·æ±‚æ•°: {stats['total_requests']}")

    # å¯åŠ¨ UI
    print("\n" + "=" * 70)
    print("å¯åŠ¨ Gradio UI")
    print("=" * 70)
    print("\nğŸš€ ä½¿ç”¨é›†æˆçš„ launch_ui() æ–¹æ³•...")
    print("   è®¿é—®åœ°å€: http://127.0.0.1:7860")
    print("\nâœ¨ è¿™æ˜¯é›†æˆåˆ° splitlearn-comm åŒ…ä¸­çš„æ–° UI åŠŸèƒ½")
    print("   ä»£ç ä» 366 è¡Œå‡å°‘åˆ° 15 è¡Œ (96% å‡å°‘)")
    print("\nPress Ctrl+C åœæ­¢\n")

    try:
        # ä½¿ç”¨æ–°çš„é›†æˆ UI æ–¹æ³•
        client.launch_ui(
            bottom_model=bottom_model,
            top_model=top_model,
            tokenizer=tokenizer,
            theme="default",  # å¯é€‰: "default", "dark", "light"
            share=False,
            server_port=7860
        )
    except KeyboardInterrupt:
        print("\n\nâœ“ UI å·²åœæ­¢")
    except ImportError as e:
        print(f"\nâŒ å¯¼å…¥é”™è¯¯: {e}")
        print("\nè¯·å®‰è£… UI ä¾èµ–:")
        print("  pip install gradio pandas")
        print("æˆ–:")
        print("  pip install -e splitlearn-comm[ui]")
        return 1
    finally:
        client.close()
        print("âœ“ è¿æ¥å·²å…³é—­")

    return 0


if __name__ == "__main__":
    exit(main())
