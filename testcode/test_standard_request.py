"""
æ ‡å‡†æ ¼å¼ ComputeRequest æµ‹è¯•è„šæœ¬
ä½¿ç”¨å®˜æ–¹æ¨èçš„ splitlearn_comm åº“è¿›è¡Œæµ‹è¯•
"""
import sys
import os
import torch
import numpy as np
import time

# ç¡®ä¿ splitlearn_comm åœ¨è·¯å¾„ä¸­
proj_root = "/Users/lhy/Desktop/Git/SL"
comm_path = os.path.join(proj_root, "splitlearn-comm", "src")
sys.path.insert(0, comm_path)

try:
    from splitlearn_comm import GRPCComputeClient
    print("âœ… æˆåŠŸå¯¼å…¥ splitlearn_comm")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ splitlearn_comm å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
    sys.exit(1)

SERVER_ADDRESS = "192.168.216.129:50053"
MODEL_ID = "gpt2-trunk"

def run_test():
    print("="*60)
    print(f"æµ‹è¯•ç›®æ ‡: {SERVER_ADDRESS} (Model: {MODEL_ID})")
    print("="*60)

    # 1. å‡†å¤‡æ•°æ®
    print("ğŸ“¦ [1/4] å‡†å¤‡è¾“å…¥æ•°æ®...")
    input_tensor = torch.randn(1, 10, 768)
    print(f"   - Tensor Shape: {tuple(input_tensor.shape)}")
    
    # éªŒè¯ä¸€ä¸‹æ•°æ®è½¬æ¢é€»è¾‘ (æ¨¡æ‹Ÿå®¢æˆ·ç«¯å†…éƒ¨è¡Œä¸º)
    try:
        array = input_tensor.cpu().numpy().astype(np.float32)
        data_bytes = array.tobytes()
        print(f"   - åºåˆ—åŒ–æ£€æŸ¥: {len(data_bytes)} bytes (é¢„æœŸ 30720)")
        if len(data_bytes) != 30720:
            print("   âš ï¸ è­¦å‘Š: æ•°æ®é•¿åº¦ä¸é¢„æœŸä¸ç¬¦ï¼")
    except Exception as e:
        print(f"   âŒ æ•°æ®åºåˆ—åŒ–æ£€æŸ¥å¤±è´¥: {e}")

    # 2. è¿æ¥
    print(f"\nğŸ”— [2/4] è¿æ¥æœåŠ¡å™¨...")
    client = GRPCComputeClient(SERVER_ADDRESS, timeout=15.0)
    
    start_conn = time.time()
    if client.connect():
        print(f"   âœ… è¿æ¥æˆåŠŸ! (è€—æ—¶ {time.time()-start_conn:.2f}s)")
    else:
        print("   âŒ è¿æ¥å¤±è´¥ (gRPCæ¡æ‰‹è¶…æ—¶)")
        return

    # 3. å‘é€è®¡ç®—è¯·æ±‚
    print(f"\nğŸš€ [3/4] å‘é€ ComputeRequest...")
    try:
        start_compute = time.time()
        output_tensor = client.compute(input_tensor, model_id=MODEL_ID)
        duration = time.time() - start_compute
        
        print(f"   ğŸ‰ è®¡ç®—æˆåŠŸ! (è€—æ—¶ {duration:.2f}s)")
        print(f"   - è¿”å› Shape: {tuple(output_tensor.shape)}")
        print("   âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"   âŒ è®¡ç®—è¯·æ±‚å¤±è´¥: {e}")
        print("   å¯èƒ½çš„æ’æŸ¥ç‚¹:")
        print("   1. æœåŠ¡ç«¯é˜²ç«å¢™æ˜¯å¦çœŸçš„å…è®¸äº† 50053 å…¥ç«™ï¼Ÿ")
        print("   2. æœåŠ¡ç«¯ç¨‹åºæ˜¯å¦å¡æ­»ï¼Ÿ(å°è¯•é‡å¯æœåŠ¡ç«¯)")
        print("   3. æœåŠ¡ç«¯æ˜¯å¦æŠ¥é”™ï¼Ÿ(çœ‹æœåŠ¡ç«¯æ§åˆ¶å°)")

    finally:
        client.disconnect()
        print("\nğŸ”Œ [4/4] è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    run_test()

æ ‡å‡†æ ¼å¼ ComputeRequest æµ‹è¯•è„šæœ¬
ä½¿ç”¨å®˜æ–¹æ¨èçš„ splitlearn_comm åº“è¿›è¡Œæµ‹è¯•
"""
import sys
import os
import torch
import numpy as np
import time

# ç¡®ä¿ splitlearn_comm åœ¨è·¯å¾„ä¸­
proj_root = "/Users/lhy/Desktop/Git/SL"
comm_path = os.path.join(proj_root, "splitlearn-comm", "src")
sys.path.insert(0, comm_path)

try:
    from splitlearn_comm import GRPCComputeClient
    print("âœ… æˆåŠŸå¯¼å…¥ splitlearn_comm")
except ImportError as e:
    print(f"âŒ å¯¼å…¥ splitlearn_comm å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
    sys.exit(1)

SERVER_ADDRESS = "192.168.216.129:50053"
MODEL_ID = "gpt2-trunk"

def run_test():
    print("="*60)
    print(f"æµ‹è¯•ç›®æ ‡: {SERVER_ADDRESS} (Model: {MODEL_ID})")
    print("="*60)

    # 1. å‡†å¤‡æ•°æ®
    print("ğŸ“¦ [1/4] å‡†å¤‡è¾“å…¥æ•°æ®...")
    input_tensor = torch.randn(1, 10, 768)
    print(f"   - Tensor Shape: {tuple(input_tensor.shape)}")
    
    # éªŒè¯ä¸€ä¸‹æ•°æ®è½¬æ¢é€»è¾‘ (æ¨¡æ‹Ÿå®¢æˆ·ç«¯å†…éƒ¨è¡Œä¸º)
    try:
        array = input_tensor.cpu().numpy().astype(np.float32)
        data_bytes = array.tobytes()
        print(f"   - åºåˆ—åŒ–æ£€æŸ¥: {len(data_bytes)} bytes (é¢„æœŸ 30720)")
        if len(data_bytes) != 30720:
            print("   âš ï¸ è­¦å‘Š: æ•°æ®é•¿åº¦ä¸é¢„æœŸä¸ç¬¦ï¼")
    except Exception as e:
        print(f"   âŒ æ•°æ®åºåˆ—åŒ–æ£€æŸ¥å¤±è´¥: {e}")

    # 2. è¿æ¥
    print(f"\nğŸ”— [2/4] è¿æ¥æœåŠ¡å™¨...")
    client = GRPCComputeClient(SERVER_ADDRESS, timeout=15.0)
    
    start_conn = time.time()
    if client.connect():
        print(f"   âœ… è¿æ¥æˆåŠŸ! (è€—æ—¶ {time.time()-start_conn:.2f}s)")
    else:
        print("   âŒ è¿æ¥å¤±è´¥ (gRPCæ¡æ‰‹è¶…æ—¶)")
        return

    # 3. å‘é€è®¡ç®—è¯·æ±‚
    print(f"\nğŸš€ [3/4] å‘é€ ComputeRequest...")
    try:
        start_compute = time.time()
        output_tensor = client.compute(input_tensor, model_id=MODEL_ID)
        duration = time.time() - start_compute
        
        print(f"   ğŸ‰ è®¡ç®—æˆåŠŸ! (è€—æ—¶ {duration:.2f}s)")
        print(f"   - è¿”å› Shape: {tuple(output_tensor.shape)}")
        print("   âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"   âŒ è®¡ç®—è¯·æ±‚å¤±è´¥: {e}")
        print("   å¯èƒ½çš„æ’æŸ¥ç‚¹:")
        print("   1. æœåŠ¡ç«¯é˜²ç«å¢™æ˜¯å¦çœŸçš„å…è®¸äº† 50053 å…¥ç«™ï¼Ÿ")
        print("   2. æœåŠ¡ç«¯ç¨‹åºæ˜¯å¦å¡æ­»ï¼Ÿ(å°è¯•é‡å¯æœåŠ¡ç«¯)")
        print("   3. æœåŠ¡ç«¯æ˜¯å¦æŠ¥é”™ï¼Ÿ(çœ‹æœåŠ¡ç«¯æ§åˆ¶å°)")

    finally:
        client.disconnect()
        print("\nğŸ”Œ [4/4] è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    run_test()


