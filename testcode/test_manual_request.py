"""
æ‰‹åŠ¨æ„é€  ComputeRequest æµ‹è¯•è„šæœ¬
å®Œå…¨æŒ‰ç…§æœåŠ¡ç«¯æ–‡æ¡£è¦æ±‚è¿›è¡Œç¼–ç 
"""
import sys
import os
import torch
import numpy as np
import grpc
import time

# å¼•å…¥ splitlearn_comm è·¯å¾„
proj_root = "/Users/lhy/Desktop/Git/SL"
sys.path.insert(0, os.path.join(proj_root, "splitlearn-comm", "src"))

try:
    # å°è¯•å¯¼å…¥åº•å±‚ protobuf å®šä¹‰
    from splitlearn_comm.proto import compute_service_pb2
    from splitlearn_comm.proto import compute_service_pb2_grpc
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ proto å®šä¹‰ï¼Œè¯·æ£€æŸ¥ splitlearn-comm æ˜¯å¦ç¼–è¯‘æ­£ç¡®")
    sys.exit(1)

SERVER_ADDRESS = "192.168.216.129:50053"
MODEL_ID = "gpt2-trunk"

def run_test():
    print(f"ğŸ”— æ­£åœ¨è¿æ¥ gRPC æœåŠ¡å™¨: {SERVER_ADDRESS}")
    
    # 1. åˆ›å»º Channel
    channel = grpc.insecure_channel(SERVER_ADDRESS)
    stub = compute_service_pb2_grpc.ComputeServiceStub(channel)
    
    # ç­‰å¾… Channel å°±ç»ª
    try:
        grpc.channel_ready_future(channel).result(timeout=5.0)
        print("âœ… gRPC Channel è¿æ¥å°±ç»ª (TCPæ¡æ‰‹æˆåŠŸ)")
    except grpc.FutureTimeoutError:
        print("âŒ gRPC Channel è¿æ¥è¶…æ—¶ (TCPæ¡æ‰‹ågRPCåè®®æœªå“åº”)")
        return

    # 2. å‡†å¤‡æ•°æ® (å®Œå…¨ç…§æ–‡æ¡£)
    print("ğŸ“¦ å‡†å¤‡æ•°æ®...")
    input_tensor = torch.randn(1, 10, 768)
    
    # è½¬æ¢: Tensor -> numpy(float32) -> bytes
    array = input_tensor.detach().cpu().numpy().astype(np.float32)
    data_bytes = array.tobytes()
    shape_list = list(input_tensor.shape)
    
    print(f"   - Shape: {shape_list}")
    print(f"   - Bytes len: {len(data_bytes)}")

    # 3. æ„é€  ComputeRequest
    request = compute_service_pb2.ComputeRequest(
        data=data_bytes,
        shape=shape_list,
        model_id=MODEL_ID,
        request_id=int(time.time())
    )

    # 4. å‘é€è¯·æ±‚
    print(f"ğŸš€ å‘é€ ComputeRequest (model_id={MODEL_ID})...")
    try:
        # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        response = stub.Compute(request, timeout=15.0)
        
        print("ğŸ‰ æ”¶åˆ°å“åº”ï¼")
        print(f"   - è®¡ç®—è€—æ—¶: {response.compute_time_ms:.2f} ms")
        print(f"   - è¾“å‡º Shape: {response.shape}")
        
        # 5. è§£æå“åº” (å¯é€‰)
        output_array = np.frombuffer(response.data, dtype=np.float32)
        output_array = output_array.reshape(response.shape)
        print(f"   - è¾“å‡ºå¼ é‡å‡å€¼: {output_array.mean():.4f}")
        print("âœ… æµ‹è¯•å®Œå…¨é€šè¿‡")
        
    except grpc.RpcError as e:
        print(f"âŒ gRPC è°ƒç”¨å¤±è´¥: {e.code()}")
        print(f"   Details: {e.details()}")

if __name__ == "__main__":
    run_test()

æ‰‹åŠ¨æ„é€  ComputeRequest æµ‹è¯•è„šæœ¬
å®Œå…¨æŒ‰ç…§æœåŠ¡ç«¯æ–‡æ¡£è¦æ±‚è¿›è¡Œç¼–ç 
"""
import sys
import os
import torch
import numpy as np
import grpc
import time

# å¼•å…¥ splitlearn_comm è·¯å¾„
proj_root = "/Users/lhy/Desktop/Git/SL"
sys.path.insert(0, os.path.join(proj_root, "splitlearn-comm", "src"))

try:
    # å°è¯•å¯¼å…¥åº•å±‚ protobuf å®šä¹‰
    from splitlearn_comm.proto import compute_service_pb2
    from splitlearn_comm.proto import compute_service_pb2_grpc
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ proto å®šä¹‰ï¼Œè¯·æ£€æŸ¥ splitlearn-comm æ˜¯å¦ç¼–è¯‘æ­£ç¡®")
    sys.exit(1)

SERVER_ADDRESS = "192.168.216.129:50053"
MODEL_ID = "gpt2-trunk"

def run_test():
    print(f"ğŸ”— æ­£åœ¨è¿æ¥ gRPC æœåŠ¡å™¨: {SERVER_ADDRESS}")
    
    # 1. åˆ›å»º Channel
    channel = grpc.insecure_channel(SERVER_ADDRESS)
    stub = compute_service_pb2_grpc.ComputeServiceStub(channel)
    
    # ç­‰å¾… Channel å°±ç»ª
    try:
        grpc.channel_ready_future(channel).result(timeout=5.0)
        print("âœ… gRPC Channel è¿æ¥å°±ç»ª (TCPæ¡æ‰‹æˆåŠŸ)")
    except grpc.FutureTimeoutError:
        print("âŒ gRPC Channel è¿æ¥è¶…æ—¶ (TCPæ¡æ‰‹ågRPCåè®®æœªå“åº”)")
        return

    # 2. å‡†å¤‡æ•°æ® (å®Œå…¨ç…§æ–‡æ¡£)
    print("ğŸ“¦ å‡†å¤‡æ•°æ®...")
    input_tensor = torch.randn(1, 10, 768)
    
    # è½¬æ¢: Tensor -> numpy(float32) -> bytes
    array = input_tensor.detach().cpu().numpy().astype(np.float32)
    data_bytes = array.tobytes()
    shape_list = list(input_tensor.shape)
    
    print(f"   - Shape: {shape_list}")
    print(f"   - Bytes len: {len(data_bytes)}")

    # 3. æ„é€  ComputeRequest
    request = compute_service_pb2.ComputeRequest(
        data=data_bytes,
        shape=shape_list,
        model_id=MODEL_ID,
        request_id=int(time.time())
    )

    # 4. å‘é€è¯·æ±‚
    print(f"ğŸš€ å‘é€ ComputeRequest (model_id={MODEL_ID})...")
    try:
        # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        response = stub.Compute(request, timeout=15.0)
        
        print("ğŸ‰ æ”¶åˆ°å“åº”ï¼")
        print(f"   - è®¡ç®—è€—æ—¶: {response.compute_time_ms:.2f} ms")
        print(f"   - è¾“å‡º Shape: {response.shape}")
        
        # 5. è§£æå“åº” (å¯é€‰)
        output_array = np.frombuffer(response.data, dtype=np.float32)
        output_array = output_array.reshape(response.shape)
        print(f"   - è¾“å‡ºå¼ é‡å‡å€¼: {output_array.mean():.4f}")
        print("âœ… æµ‹è¯•å®Œå…¨é€šè¿‡")
        
    except grpc.RpcError as e:
        print(f"âŒ gRPC è°ƒç”¨å¤±è´¥: {e.code()}")
        print(f"   Details: {e.details()}")

if __name__ == "__main__":
    run_test()


