# Split Learning è®­ç»ƒåŠŸèƒ½å®ç° - å¿«é€Ÿå‚è€ƒ

## ğŸ¯ æ ¸å¿ƒå·¥ä½œæ¸…å•

### 1. åŸºç¡€ä¿®æ”¹ï¼ˆå¿…é¡»å®Œæˆï¼‰

#### 1.1 ç§»é™¤æ¨ç†æ¨¡å¼é™åˆ¶
```python
# âŒ å½“å‰ä»£ç 
bottom.eval()
with torch.no_grad():
    output = model(input)

# âœ… ä¿®æ”¹ä¸º
bottom.train()  # æˆ–æ ¹æ®é…ç½®åŠ¨æ€è®¾ç½®
output = model(input)  # ç§»é™¤ no_grad
```

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**:
- `test/client/test_client.py` (ç¬¬87, 94, 141, 180è¡Œ)
- `test/client/interactive_client.py` (ç¬¬77, 84, 138è¡Œ)

#### 1.2 æ·»åŠ è®­ç»ƒé…ç½®ç±»
åˆ›å»º `test/client/training_config.py`:
- ä¼˜åŒ–å™¨é…ç½®
- å­¦ä¹ ç‡é…ç½®
- æŸå¤±å‡½æ•°é…ç½®
- è®­ç»ƒå‚æ•°é…ç½®

---

### 2. é€šä¿¡åè®®æ‰©å±•ï¼ˆæ ¸å¿ƒå·¥ä½œï¼‰

#### 2.1 æ‰©å±• Protocol Buffer

**æ–‡ä»¶**: `SplitLearnComm/src/splitlearn_comm/protocol/compute_service.proto`

**éœ€è¦æ·»åŠ çš„æ¶ˆæ¯ç±»å‹**:
```protobuf
message BackwardRequest {
    bytes gradient_data = 1;
    TensorShape gradient_shape = 2;
    string request_id = 3;
}

message BackwardResponse {
    bytes gradient_data = 1;
    TensorShape gradient_shape = 2;
    bool success = 3;
}
```

#### 2.2 å®ç°æ¢¯åº¦åºåˆ—åŒ–å·¥å…·

**æ–°å»ºæ–‡ä»¶**: `SplitLearnComm/src/splitlearn_comm/utils/gradient_utils.py`
- `serialize_gradient()`: åºåˆ—åŒ–æ¢¯åº¦å¼ é‡
- `deserialize_gradient()`: ååºåˆ—åŒ–æ¢¯åº¦å¼ é‡
- æ”¯æŒå‹ç¼©ä»¥å‡å°‘ç½‘ç»œä¼ è¾“

#### 2.3 æ‰©å±• gRPC æœåŠ¡æ¥å£

**ä¿®æ”¹**: `SplitLearnComm/src/splitlearn_comm/protocol/compute_service.proto`

**æ·»åŠ æœåŠ¡æ–¹æ³•**:
```protobuf
service ComputeService {
    rpc Compute(ComputeRequest) returns (ComputeResponse);
    
    // æ–°å¢
    rpc Backward(BackwardRequest) returns (BackwardResponse);
    rpc GetGradients(GradientRequest) returns (GradientResponse);
}
```

---

### 3. å®¢æˆ·ç«¯è®­ç»ƒæ”¯æŒ

#### 3.1 åˆ›å»ºè®­ç»ƒå®¢æˆ·ç«¯

**æ–°å»ºæ–‡ä»¶**: `SplitLearnComm/src/splitlearn_comm/training_client.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- å‰å‘ä¼ æ’­ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
- åå‘ä¼ æ’­ï¼ˆä¼ é€’æ¢¯åº¦ï¼‰
- è¯·æ±‚IDç®¡ç†ï¼ˆå…³è”å‰å‘å’Œåå‘ï¼‰
- ä¸­é—´çŠ¶æ€ç¼“å­˜

#### 3.2 åˆ›å»ºè®­ç»ƒå™¨ç±»

**æ–°å»ºæ–‡ä»¶**: `test/client/training_client.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- è®­ç»ƒæ­¥éª¤ï¼ˆforward + backward + updateï¼‰
- è®­ç»ƒå¾ªç¯ï¼ˆepoch loopï¼‰
- æŸå¤±è®¡ç®—
- ä¼˜åŒ–å™¨ç®¡ç†
- æ£€æŸ¥ç‚¹ä¿å­˜

---

### 4. æœåŠ¡å™¨ç«¯è®­ç»ƒæ”¯æŒ

#### 4.1 æ‰©å±•æœåŠ¡å™¨ç±»

**ä¿®æ”¹**: `SplitLearnManager/src/splitlearn_manager/server/managed_server.py`

**éœ€è¦æ·»åŠ **:
- è®­ç»ƒæ¨¡å¼æ”¯æŒ
- å‰å‘ä¼ æ’­çŠ¶æ€ç¼“å­˜
- åå‘ä¼ æ’­å¤„ç†
- ä¼˜åŒ–å™¨ç®¡ç†

#### 4.2 å®ç°æ¢¯åº¦å¤„ç†

**æ ¸å¿ƒé€»è¾‘**:
```python
def backward(self, gradient, request_id):
    # 1. ä»ç¼“å­˜è·å–å‰å‘ä¼ æ’­çŠ¶æ€
    cache = self._forward_cache[request_id]
    
    # 2. é‡æ–°å‰å‘ä¼ æ’­ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
    output = model(cache['input'])
    
    # 3. åå‘ä¼ æ’­
    output.backward(gradient=gradient)
    
    # 4. è·å–è¾“å…¥æ¢¯åº¦
    input_gradient = cache['input'].grad
    
    # 5. æ›´æ–°å‚æ•°
    optimizer.step()
    
    return input_gradient
```

---

### 5. å®Œæ•´è®­ç»ƒæµç¨‹

#### 5.1 è®­ç»ƒæ­¥éª¤æµç¨‹

```
1. æ¸…é›¶æ¢¯åº¦
   optimizer.zero_grad()

2. å‰å‘ä¼ æ’­
   hidden_1 = bottom(input)
   hidden_2 = trunk_client.forward(hidden_1, request_id)
   output = top(hidden_2)

3. è®¡ç®—æŸå¤±
   loss = criterion(output, labels)

4. åå‘ä¼ æ’­
   loss.backward()
   grad_hidden_2 = hidden_2.grad
   grad_hidden_1 = trunk_client.backward(grad_hidden_2, request_id)
   hidden_1.backward(grad_hidden_1)

5. æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼‰
   clip_grad_norm()

6. å‚æ•°æ›´æ–°
   optimizer_bottom.step()
   optimizer_top.step()
```

#### 5.2 æ•°æ®åŠ è½½

**æ–°å»ºæ–‡ä»¶**: `test/data/dataset.py`
- æ–‡æœ¬æ•°æ®é›†ç±»
- DataLoader å°è£…

---

## ğŸ“‹ å®æ–½æ¸…å•

### Phase 1: åŸºç¡€å‡†å¤‡ âœ…
- [ ] åˆ›å»º `TrainingConfig` ç±»
- [ ] ä¿®æ”¹æ¨¡å‹æ¨¡å¼ç®¡ç†ï¼ˆæ”¯æŒ train/eval åˆ‡æ¢ï¼‰
- [ ] ç§»é™¤ `torch.no_grad()` é™åˆ¶
- [ ] æœ¬åœ°è®­ç»ƒæµ‹è¯•ï¼ˆå•æœºï¼Œä¸æ¶‰åŠç½‘ç»œï¼‰

### Phase 2: é€šä¿¡åè®® âš ï¸
- [ ] æ‰©å±• Protocol Buffer å®šä¹‰
- [ ] å®ç°æ¢¯åº¦åºåˆ—åŒ–å·¥å…·
- [ ] é‡æ–°ç”Ÿæˆ gRPC ä»£ç 
- [ ] æµ‹è¯•æ¢¯åº¦åºåˆ—åŒ–/ååºåˆ—åŒ–

### Phase 3: å®¢æˆ·ç«¯è®­ç»ƒæ”¯æŒ âš ï¸
- [ ] åˆ›å»º `TrainingClient` ç±»
- [ ] å®ç°å‰å‘ä¼ æ’­ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
- [ ] å®ç°åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ä¼ é€’ï¼‰
- [ ] åˆ›å»º `SplitLearningTrainer` ç±»
- [ ] å®ç°è®­ç»ƒå¾ªç¯

### Phase 4: æœåŠ¡å™¨ç«¯è®­ç»ƒæ”¯æŒ âš ï¸
- [ ] æ‰©å±• `ManagedServer` ç±»
- [ ] å®ç°å‰å‘ä¼ æ’­çŠ¶æ€ç¼“å­˜
- [ ] å®ç°åå‘ä¼ æ’­å¤„ç†
- [ ] æ·»åŠ ä¼˜åŒ–å™¨æ”¯æŒ
- [ ] æµ‹è¯•æœåŠ¡å™¨ç«¯è®­ç»ƒ

### Phase 5: é›†æˆæµ‹è¯• âš ï¸
- [ ] ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯•
- [ ] æ¢¯åº¦ä¼ é€’æ­£ç¡®æ€§éªŒè¯
- [ ] å‚æ•°æ›´æ–°éªŒè¯
- [ ] æ€§èƒ½æµ‹è¯•

---

## ğŸ”‘ å…³é”®æŠ€æœ¯ç‚¹

### 1. æ¢¯åº¦ä¼ é€’æµç¨‹

```
Topæ¨¡å‹ â†’ è®¡ç®—æ¢¯åº¦ â†’ grad_hidden_2
                            â†“
                    ç½‘ç»œä¼ è¾“ï¼ˆåºåˆ—åŒ–ï¼‰
                            â†“
TrunkæœåŠ¡å™¨ â†’ åå‘ä¼ æ’­ â†’ grad_hidden_1
                            â†“
                    ç½‘ç»œä¼ è¾“ï¼ˆåºåˆ—åŒ–ï¼‰
                            â†“
Bottomæ¨¡å‹ â†’ æ¥æ”¶æ¢¯åº¦ â†’ æ›´æ–°å‚æ•°
```

### 2. çŠ¶æ€ç¼“å­˜æœºåˆ¶

**ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜ï¼Ÿ**
- åå‘ä¼ æ’­éœ€è¦å‰å‘ä¼ æ’­çš„ä¸­é—´çŠ¶æ€
- éœ€è¦ä¿å­˜è¾“å…¥å¼ é‡ç”¨äºé‡æ–°è®¡ç®—

**ç¼“å­˜å†…å®¹**:
```python
{
    'request_id': {
        'input': tensor,      # è¾“å…¥å¼ é‡
        'output': tensor,     # è¾“å‡ºå¼ é‡
        'model_name': str,    # æ¨¡å‹åç§°
        'timestamp': float    # æ—¶é—´æˆ³ï¼ˆç”¨äºæ¸…ç†ï¼‰
    }
}
```

### 3. è¯·æ±‚IDå…³è”

**ç”¨é€”**: å°†å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å…³è”èµ·æ¥

```python
# å‰å‘ä¼ æ’­
request_id = uuid.uuid4().hex
output = client.forward(input, request_id=request_id)

# åå‘ä¼ æ’­ï¼ˆä½¿ç”¨ç›¸åŒçš„ request_idï¼‰
gradient = client.backward(output_grad, request_id=request_id)
```

---

## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: å†…å­˜ä¸è¶³
**A**: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ã€æ··åˆç²¾åº¦è®­ç»ƒã€å‡å°‘æ‰¹æ¬¡å¤§å°

### Q2: æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸
**A**: ä½¿ç”¨æ¢¯åº¦è£å‰ªã€å­¦ä¹ ç‡è°ƒåº¦ã€æ¢¯åº¦å½’ä¸€åŒ–

### Q3: è®­ç»ƒä¸ç¨³å®š
**A**: è°ƒæ•´å­¦ä¹ ç‡ã€ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨ã€å¢åŠ æ¢¯åº¦è£å‰ª

### Q4: ç½‘ç»œå»¶è¿Ÿå½±å“æ€§èƒ½
**A**: ä½¿ç”¨å¼‚æ­¥é€šä¿¡ã€æ‰¹é‡æ¢¯åº¦ä¼ è¾“ã€æ¢¯åº¦å‹ç¼©

---

## ğŸ“š å‚è€ƒæ–‡ä»¶

è¯¦ç»†å®ç°æŒ‡å—: `test/TRAINING_IMPLEMENTATION_GUIDE.md`

åŒ…å«:
- å®Œæ•´çš„ä»£ç ç¤ºä¾‹
- è¯¦ç»†çš„å®ç°æ­¥éª¤
- æ¶æ„è®¾è®¡è¯´æ˜
- æµ‹è¯•æ–¹æ³•
- é—®é¢˜è§£å†³æ–¹æ¡ˆ

---

## â±ï¸ é¢„è®¡å·¥ä½œé‡

| é˜¶æ®µ | å·¥ä½œé‡ | éš¾åº¦ |
|------|--------|------|
| Phase 1: åŸºç¡€å‡†å¤‡ | 1-2å‘¨ | â­â­ |
| Phase 2: é€šä¿¡åè®® | 2-3å‘¨ | â­â­â­â­ |
| Phase 3: å®¢æˆ·ç«¯æ”¯æŒ | 2-3å‘¨ | â­â­â­ |
| Phase 4: æœåŠ¡å™¨æ”¯æŒ | 2-3å‘¨ | â­â­â­â­ |
| Phase 5: æµ‹è¯•ä¼˜åŒ– | 2-3å‘¨ | â­â­â­ |

**æ€»è®¡**: çº¦ 9-14 å‘¨ï¼ˆ2-3.5ä¸ªæœˆï¼‰

---

## ğŸ“ å­¦ä¹ èµ„æº

1. **PyTorch åˆ†å¸ƒå¼è®­ç»ƒ**:
   - PyTorch å®˜æ–¹æ–‡æ¡£: Distributed Training
   
2. **Split Learning è®ºæ–‡**:
   - "Split Learning for Health: Distributed Deep Learning without Sharing Raw Patient Data"

3. **gRPC é«˜çº§ç‰¹æ€§**:
   - gRPC æµå¼ä¼ è¾“
   - gRPC å¼‚æ­¥è°ƒç”¨

---

## ğŸ’¡ å¿«é€Ÿå¼€å§‹

1. **é˜…è¯»è¯¦ç»†æŒ‡å—**: `TRAINING_IMPLEMENTATION_GUIDE.md`
2. **ä» Phase 1 å¼€å§‹**: å®ç°åŸºç¡€è®­ç»ƒåŠŸèƒ½ï¼ˆä¸æ¶‰åŠç½‘ç»œï¼‰
3. **é€æ­¥æ‰©å±•**: æŒ‰ç…§æ¸…å•é€é¡¹å®Œæˆ
4. **å……åˆ†æµ‹è¯•**: æ¯ä¸ªé˜¶æ®µéƒ½è¦è¿›è¡Œæµ‹è¯•

---

## âœ… æˆåŠŸæ ‡å‡†

è®­ç»ƒåŠŸèƒ½å®ç°æˆåŠŸçš„æ ‡å¿—ï¼š

1. âœ… èƒ½å¤Ÿæ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæ­¥éª¤
2. âœ… æ¢¯åº¦èƒ½å¤Ÿæ­£ç¡®ä¼ é€’ï¼ˆå®¢æˆ·ç«¯ â†” æœåŠ¡å™¨ï¼‰
3. âœ… æ¨¡å‹å‚æ•°èƒ½å¤Ÿæ­£ç¡®æ›´æ–°
4. âœ… è®­ç»ƒæŸå¤±èƒ½å¤Ÿæ­£å¸¸ä¸‹é™
5. âœ… æ”¯æŒæ£€æŸ¥ç‚¹ä¿å­˜å’Œæ¢å¤
6. âœ… æ”¯æŒè®­ç»ƒå’Œæ¨ç†æ¨¡å¼åˆ‡æ¢
