# Split Learning 训练架构设计图

## 系统架构概览

```
┌─────────────────────────────────────────────────────────────────┐
│                        训练客户端 (Client)                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                   │
│  ┌──────────────┐          ┌──────────────┐                     │
│  │ Bottom Model │          │  Top Model   │                     │
│  │  (可训练)    │          │  (可训练)    │                     │
│  └──────┬───────┘          └──────┬───────┘                     │
│         │                         │                             │
│         │ hidden_1                │ hidden_2                    │
│         │ (前向)                  │ (前向)                      │
│         ↓                         ↓                             │
│  ┌──────────────────────────────────────────┐                  │
│  │      Training Client (训练客户端)         │                  │
│  │  - 管理前后向传播                        │                  │
│  │  - 处理梯度传递                          │                  │
│  │  - 优化器管理                            │                  │
│  └──────────────┬───────────────────────────┘                  │
│                 │                                               │
│                 │ gRPC (前向/反向)                              │
│                 ↓                                               │
└─────────────────┼───────────────────────────────────────────────┘
                  │
                  │ 网络传输
                  │
┌─────────────────┼───────────────────────────────────────────────┐
│                 │                                                │
│                 ↓                                                │
│  ┌──────────────────────────────────────────┐                   │
│  │      Training Server (训练服务器)         │                   │
│  │  - 处理前向传播                          │                   │
│  │  - 处理反向传播                          │                   │
│  │  - 状态缓存管理                          │                   │
│  │  - 优化器管理                            │                   │
│  └──────────────┬───────────────────────────┘                   │
│                 │                                                │
│                 │                                                │
│  ┌──────────────▼──────────────┐                                │
│  │      Trunk Model            │                                │
│  │       (可训练)              │                                │
│  └─────────────────────────────┘                                │
│                                                                   │
└──────────────────────────────────────────────────────────────────┘
```

## 前向传播流程

```
┌──────────────────────────────────────────────────────────────────┐
│  前向传播 (Forward Pass)                                          │
└──────────────────────────────────────────────────────────────────┘

客户端                         网络传输                    服务器
  │                                                           │
  │ 1. 输入数据                                              │
  │    input_ids [B, L]                                      │
  │      │                                                   │
  │      ▼                                                   │
  │ 2. Bottom Model                                          │
  │    ┌─────────────┐                                       │
  │    │ Embedding   │                                       │
  │    │ Blocks 0-1  │                                       │
  │    └──────┬──────┘                                       │
  │           │                                               │
  │           │ hidden_1 [B, L, H]                           │
  │           │      │                                       │
  │           │      ▼                                       │
  │           │ ┌─────────────────────┐                      │
  │           │ │ 序列化 + 压缩        │                      │
  │           │ └──────────┬──────────┘                      │
  │           │            │                                  │
  └───────────┼────────────┼──────────────────────────────────┘
              │            │
              │   gRPC     │
              │   Compute  │
              │            │
┌─────────────┼────────────┼──────────────────────────────────┐
│             │            │                                  │
│             │            ▼                                  │
│             │     ┌──────────────┐                         │
│             │     │ 反序列化      │                         │
│             │     └──────┬───────┘                         │
│             │            │                                  │
│             │            │ hidden_1 [B, L, H]              │
│             │            ▼                                  │
│             │     3. Trunk Model                           │
│             │        ┌─────────────┐                       │
│             │        │ Blocks 2-9  │                       │
│             │        └──────┬──────┘                       │
│             │               │                              │
│             │               │ hidden_2 [B, L, H]           │
│             │               ▼                              │
│             │        ┌──────────────┐                      │
│             │        │ 序列化 + 压缩 │                      │
│             │        └──────┬───────┘                      │
│             │               │                              │
└─────────────┼───────────────┼──────────────────────────────┘
              │               │
              │   gRPC        │
              │   Compute     │
              │   Response    │
              │               │
┌─────────────┼───────────────┼──────────────────────────────┐
│             │               │                              │
│             │               ▼                              │
│             │        ┌──────────────┐                      │
│             │        │ 反序列化      │                      │
│             │        └──────┬───────┘                      │
│             │               │                              │
│             │               │ hidden_2 [B, L, H]           │
│             │               ▼                              │
│             │       4. Top Model                           │
│             │          ┌─────────────┐                     │
│             │          │ Blocks 10-11│                     │
│             │          │ Layer Norm  │                     │
│             │          │ LM Head     │                     │
│             │          └──────┬──────┘                     │
│             │                 │                            │
│             │                 │ logits [B, L, V]           │
│             │                 ▼                            │
│             │         5. 计算损失                           │
│             │            loss = criterion(logits, labels)  │
│             │                                               │
└─────────────┼───────────────────────────────────────────────┘
              │
              │
```

## 反向传播流程

```
┌──────────────────────────────────────────────────────────────────┐
│  反向传播 (Backward Pass)                                         │
└──────────────────────────────────────────────────────────────────┘

客户端                         网络传输                    服务器
  │                                                           │
  │ 1. 损失反向传播                                           │
  │    loss.backward()                                       │
  │      │                                                   │
  │      ▼                                                   │
  │ 2. Top Model 梯度                                        │
  │    ┌─────────────┐                                       │
  │    │ ∂loss/∂h2   │                                       │
  │    └──────┬──────┘                                       │
  │           │                                               │
  │           │ grad_hidden_2 [B, L, H]                      │
  │           │      │                                       │
  │           │      ▼                                       │
  │           │ ┌─────────────────────┐                      │
  │           │ │ 序列化梯度 + 压缩    │                      │
  │           │ └──────────┬──────────┘                      │
  │           │            │                                  │
  │           │            │                                  │
  │           │  生成 request_id                             │
  │           │      │                                       │
  └───────────┼──────┼───────────────────────────────────────┘
              │      │
              │   gRPC Backward
              │   (grad_hidden_2, request_id)
              │
┌─────────────┼──────┼───────────────────────────────────────┐
│             │      │                                       │
│             │      ▼                                       │
│             │ ┌──────────────┐                            │
│             │ │ 反序列化梯度  │                            │
│             │ └──────┬───────┘                            │
│             │        │                                    │
│             │        │ grad_hidden_2 [B, L, H]           │
│             │        ▼                                    │
│             │ 3. Trunk Model 反向传播                     │
│             │    ┌─────────────┐                          │
│             │    │ 从缓存获取   │                          │
│             │    │ 前向状态     │                          │
│             │    └──────┬──────┘                          │
│             │           │                                 │
│             │           │ 重新前向传播（保留梯度）         │
│             │           │ hidden_2 = trunk(hidden_1)      │
│             │           │                                 │
│             │           │ 反向传播                        │
│             │           │ hidden_2.backward(grad_h2)      │
│             │           │                                 │
│             │           │ 获取输入梯度                    │
│             │           │ grad_hidden_1 = h1.grad         │
│             │           │                                 │
│             │           │ 更新 Trunk 参数                 │
│             │           │ optimizer_trunk.step()          │
│             │           │                                 │
│             │           │ grad_hidden_1 [B, L, H]         │
│             │           ▼                                 │
│             │    ┌──────────────┐                         │
│             │    │ 序列化梯度    │                         │
│             │    └──────┬───────┘                         │
│             │           │                                 │
└─────────────┼───────────┼─────────────────────────────────┘
              │           │
              │   gRPC Backward Response
              │   (grad_hidden_1)
              │
┌─────────────┼───────────┼─────────────────────────────────┐
│             │           │                                 │
│             │           ▼                                 │
│             │    ┌──────────────┐                         │
│             │    │ 反序列化梯度  │                         │
│             │    └──────┬───────┘                         │
│             │           │                                 │
│             │           │ grad_hidden_1 [B, L, H]         │
│             │           ▼                                 │
│             │   4. Bottom Model 反向传播                  │
│             │      ┌─────────────┐                        │
│             │      │ 传递梯度到   │                        │
│             │      │ Bottom      │                        │
│             │      └──────┬──────┘                        │
│             │             │                               │
│             │             │ hidden_1.backward(grad_h1)    │
│             │             │                               │
│             │             │ 5. 更新 Bottom 参数           │
│             │             │    optimizer_bottom.step()    │
│             │             │                               │
│             │             │ 6. 更新 Top 参数              │
│             │             │    optimizer_top.step()       │
│             │                                               │
└─────────────┼───────────────────────────────────────────────┘
              │
              │ 完成一个训练步骤
              │
```

## 关键组件交互

```
┌─────────────────────────────────────────────────────────────┐
│                    训练客户端组件                              │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           SplitLearningTrainer                      │   │
│  │  ┌──────────────┐  ┌──────────────┐                │   │
│  │  │ Optimizer    │  │ Loss         │                │   │
│  │  │ (Bottom)     │  │ Function     │                │   │
│  │  └──────┬───────┘  └──────┬───────┘                │   │
│  │         │                  │                        │   │
│  │         │                  │                        │   │
│  │  ┌──────▼──────────────────▼───────┐               │   │
│  │  │     train_step()                │               │   │
│  │  │  - Forward                      │               │   │
│  │  │  - Loss                         │               │   │
│  │  │  - Backward                     │               │   │
│  │  │  - Update                       │               │   │
│  │  └─────────────────────────────────┘               │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         TrainingClient                              │   │
│  │  - forward(input, request_id)                       │   │
│  │  - backward(gradient, request_id)                   │   │
│  │  - _forward_cache {request_id: state}               │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐                         │
│  │ Bottom Model │  │  Top Model   │                         │
│  │  (trainable) │  │  (trainable) │                         │
│  └──────────────┘  └──────────────┘                         │
│                                                               │
└─────────────────────────────────────────────────────────────┘
                              │
                              │ gRPC
                              │
┌─────────────────────────────▼─────────────────────────────┐
│                  训练服务器组件                              │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         ManagedTrainingServer                        │   │
│  │  - compute_with_grad(input, request_id)             │   │
│  │  - backward(gradient, request_id)                   │   │
│  │  - _forward_cache {request_id: state}               │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         Trunk Model                                  │   │
│  │  - Forward (with gradient tracking)                 │   │
│  │  - Backward (compute gradients)                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         Optimizer (Trunk)                            │   │
│  │  - step()                                           │   │
│  │  - zero_grad()                                      │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

## 数据流图

```
训练一个批次的数据流：

输入数据 [B, L]
    │
    ▼
┌─────────────────┐
│  Tokenization   │
└────────┬────────┘
         │
         │ input_ids [B, L]
         ▼
┌─────────────────┐      hidden_1 [B, L, H]      ┌─────────────────┐
│  Bottom Model   │ ────────────────────────────> │  Trunk Server   │
│  (Forward)      │                              │  (Forward)      │
└─────────────────┘                              └────────┬────────┘
                                                           │
                                                           │ hidden_2 [B, L, H]
                                                           ▼
                                                  ┌─────────────────┐
                                                  │   Top Model     │
                                                  │   (Forward)     │
                                                  └────────┬────────┘
                                                           │
                                                           │ logits [B, L, V]
                                                           ▼
                                                  ┌─────────────────┐
                                                  │  Loss Function  │
                                                  └────────┬────────┘
                                                           │
                                                           │ loss (scalar)
                                                           ▼
                                                  ┌─────────────────┐
                                                  │   Backward      │
                                                  └────────┬────────┘
                                                           │
                    ┌──────────────────────────────────────┴──────────┐
                    │                                                 │
                    ▼                                                 ▼
         ┌──────────────────┐                          ┌──────────────────┐
         │ grad_hidden_2    │                          │ grad_hidden_2    │
         │ [B, L, H]        │                          │ [B, L, H]        │
         └────────┬─────────┘                          └────────┬─────────┘
                  │                                            │
                  │ 传递到 Top                                  │ 网络传输到服务器
                  ▼                                            ▼
         ┌──────────────────┐                          ┌──────────────────┐
         │  Top Backward    │                          │ Trunk Backward   │
         └────────┬─────────┘                          └────────┬─────────┘
                  │                                            │
                  │ grad_hidden_1                             │ grad_hidden_1
                  │ (通过网络获取)                             │ [B, L, H]
                  ▼                                            │
         ┌──────────────────┐                          ┌───────┴───────────┐
         │ Bottom Backward  │                          │ 更新 Trunk 参数   │
         └────────┬─────────┘                          └───────────────────┘
                  │
                  ▼
         ┌──────────────────┐
         │ 更新 Bottom 参数 │
         └────────┬─────────┘
                  │
                  ▼
         ┌──────────────────┐
         │ 更新 Top 参数    │
         └──────────────────┘
```

## 关键技术点

### 1. 请求ID关联机制

```
前向传播:
  request_id = generate_id()
  cache[request_id] = {
      'input': input_tensor,
      'timestamp': time()
  }
  output = forward(input, request_id)

反向传播:
  gradient = backward(output_grad, request_id)
  # 使用相同的 request_id 从缓存获取前向状态
```

### 2. 梯度序列化格式

```
梯度张量 → NumPy数组 → Pickle序列化 → 压缩 → 字节流
                                                ↓
                                          网络传输
                                                ↓
字节流 → 解压缩 → Pickle反序列化 → NumPy数组 → PyTorch张量
```

### 3. 状态缓存管理

```
缓存结构:
{
    'request_id_1': {
        'input': tensor,        # 输入张量
        'output': tensor,       # 输出张量（可选）
        'model_name': 'trunk',  # 模型名称
        'timestamp': 12345.67   # 时间戳
    },
    ...
}

清理策略:
- 反向传播完成后立即删除
- 定期清理过期缓存（>5分钟）
- 限制缓存大小（最多1000个条目）
```

## 性能优化策略

### 1. 异步通信
```
前向传播可以异步执行，不阻塞训练循环
```

### 2. 梯度压缩
```
使用量化、稀疏化等方法减少梯度大小
```

### 3. 批量梯度传输
```
累积多个步骤的梯度，批量传输
```

### 4. 混合精度训练
```
使用 FP16 减少内存和传输开销
```

---

这份架构图帮助理解整个训练系统的设计和工作流程。
