#!/usr/bin/env python3
"""
æ£€æŸ¥ LoRA å¾®è°ƒæµ‹è¯•çš„ä¾èµ–ç¯å¢ƒ

åªæ£€æŸ¥ï¼Œä¸å®‰è£…ä»»ä½•åŒ…
"""

import sys

print("=" * 70)
print("LoRA å¾®è°ƒæµ‹è¯• - ä¾èµ–ç¯å¢ƒæ£€æŸ¥")
print("=" * 70)
print()

all_ok = True

# æ£€æŸ¥ PEFT åº“ï¼ˆå¿…éœ€ï¼‰
print("1. æ£€æŸ¥ PEFT åº“ï¼ˆå¿…éœ€ï¼‰...")
try:
    import peft
    print(f"   âœ… PEFT å·²å®‰è£… (ç‰ˆæœ¬: {peft.__version__})")
except ImportError:
    print("   âŒ PEFT æœªå®‰è£…")
    print("   ğŸ“ å®‰è£…å‘½ä»¤: pip install peft")
    all_ok = False

# æ£€æŸ¥ datasets åº“ï¼ˆå¯é€‰ï¼‰
print("\n2. æ£€æŸ¥ datasets åº“ï¼ˆå¯é€‰ï¼‰...")
try:
    import datasets
    print(f"   âœ… datasets å·²å®‰è£… (ç‰ˆæœ¬: {datasets.__version__})")
    print("   â„¹ï¸  å¯ä»¥ä½¿ç”¨ HuggingFace datasets")
except ImportError:
    print("   âš ï¸  datasets æœªå®‰è£…ï¼ˆå¯ä»¥ä½¿ç”¨åˆæˆæ•°æ®é›†ï¼‰")
    print("   ğŸ“ å®‰è£…å‘½ä»¤: pip install datasets")

# æ£€æŸ¥ transformers
print("\n3. æ£€æŸ¥ transformers åº“...")
try:
    import transformers
    print(f"   âœ… transformers å·²å®‰è£… (ç‰ˆæœ¬: {transformers.__version__})")
except ImportError:
    print("   âŒ transformers æœªå®‰è£…")
    all_ok = False

# æ£€æŸ¥ torch
print("\n4. æ£€æŸ¥ PyTorch...")
try:
    import torch
    print(f"   âœ… PyTorch å·²å®‰è£… (ç‰ˆæœ¬: {torch.__version__})")
except ImportError:
    print("   âŒ PyTorch æœªå®‰è£…")
    all_ok = False

# æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
print("\n5. æ£€æŸ¥ Trunk æœåŠ¡å™¨...")
import os
from pathlib import Path

pid_file = Path(__file__).parent / ".trunk.pid"
if pid_file.exists():
    try:
        pid = int(pid_file.read_text().strip())
        import subprocess
        result = subprocess.run(
            ["ps", "-p", str(pid), "-o", "pid,command"],
            capture_output=True,
            text=True
        )
        if result.returncode == 0:
            print(f"   âœ… Trunk æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ (PID: {pid})")
        else:
            print(f"   âš ï¸  æœåŠ¡å™¨ PID æ–‡ä»¶å­˜åœ¨ä½†è¿›ç¨‹æœªè¿è¡Œ")
            all_ok = False
    except Exception as e:
        print(f"   âš ï¸  æ— æ³•æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€: {e}")
else:
    print("   âš ï¸  æœåŠ¡å™¨æœªè¿è¡Œ")
    print("   ğŸ“ å¯åŠ¨å‘½ä»¤: bash test/start_all.sh")
    all_ok = False

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
print("\n6. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
project_root = Path(__file__).parent.parent
models_dir = project_root / "models"

required_files = [
    "bottom/gpt2_2-10_bottom.pt",
    "top/gpt2_2-10_top.pt",
    "bottom/gpt2_2-10_bottom_metadata.json",
    "top/gpt2_2-10_top_metadata.json"
]

all_files_exist = True
for file_path in required_files:
    full_path = models_dir / file_path
    if full_path.exists():
        print(f"   âœ… {file_path}")
    else:
        print(f"   âŒ {file_path} ä¸å­˜åœ¨")
        all_files_exist = False

if not all_files_exist:
    all_ok = False

# æ€»ç»“
print("\n" + "=" * 70)
if all_ok:
    print("âœ… æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ï¼Œå¯ä»¥è¿è¡Œæµ‹è¯•ï¼")
    print("\nè¿è¡Œæµ‹è¯•:")
    print("  python test/client/train_lora_simple.py")
    print("  æˆ–")
    print("  bash test/run_lora_training.sh")
else:
    print("âŒ éƒ¨åˆ†ä¾èµ–ç¼ºå¤±ï¼Œè¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–")
    print("\nå¿…éœ€çš„ä¾èµ–:")
    print("  pip install peft")
    print("\nå¯é€‰çš„ä¾èµ–:")
    print("  pip install datasets  # å¦‚æœè¦ä½¿ç”¨ HuggingFace datasets")
print("=" * 70)

sys.exit(0 if all_ok else 1)
