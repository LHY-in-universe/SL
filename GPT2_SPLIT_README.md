# GPT-2 åˆ†æ‹†å­¦ä¹ ç³»ç»Ÿ

åŸºäº `SplitLearnCore` å’Œ `SplitLearnComm` å®ç°çš„ GPT-2 åˆ†æ‹†å­¦ä¹ æ–¹æ¡ˆï¼Œæ”¯æŒ KV Cacheã€æ€§èƒ½ç›‘æ§å’Œå®Œæ•´çš„ç»Ÿè®¡åˆ†æã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

### Python è„šæœ¬
- `gpt2_server_grpc.py` - åˆ†æ‹†æ¨¡å‹æœåŠ¡ç«¯ï¼ˆTrunk æ¨¡å‹ï¼Œlayers 2-9ï¼‰
- `gpt2_client_gradio_grpc.py` - åˆ†æ‹†æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆBottom + Topï¼Œå¸¦ Gradio UIï¼‰
- `gpt2_full_model_gradio.py` - å®Œæ•´æ¨¡å‹å¯¹ç…§ç»„ï¼ˆç”¨äºæ€§èƒ½å¯¹æ¯”ï¼‰

### å¯åŠ¨è„šæœ¬
- `run_gpt2_server.sh` - å¯åŠ¨æœåŠ¡ç«¯
- `run_gpt2_client.sh` - å¯åŠ¨å®¢æˆ·ç«¯
- `run_gpt2_full.sh` - å¯åŠ¨å®Œæ•´æ¨¡å‹

### å…¶ä»–
- `logs/` - æ—¥å¿—ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
  - `gpt2_server.log` - æœåŠ¡ç«¯æ—¥å¿—
  - `gpt2_client.log` - å®¢æˆ·ç«¯æ—¥å¿—
  - `gpt2_full.log` - å®Œæ•´æ¨¡å‹æ—¥å¿—

---

## ğŸ—ï¸ æ¶æ„è¯´æ˜

### åˆ†æ‹†æ¨¡å‹æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å®¢æˆ·ç«¯ (æœ¬åœ°)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Bottom   â”‚ â”‚  â† å‰ 2 å±‚ (layers 0-1) + embeddings
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â†“        â”‚
â”‚  [ gRPC ç½‘ç»œ ] â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Trunk    â”‚ â”‚  â† ä¸­é—´ 8 å±‚ (layers 2-9) - è¿œç¨‹æœåŠ¡å™¨
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â†“        â”‚
â”‚  [ gRPC ç½‘ç»œ ] â”‚
â”‚        â†“        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Top     â”‚ â”‚  â† å 2 å±‚ (layers 10-11) + norm + LM head
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®Œæ•´æ¨¡å‹æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ¬åœ°è¿è¡Œ (å•æœº) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  GPT-2 12å±‚ â”‚ â”‚  â† å®Œæ•´çš„ GPT-2 æ¨¡å‹
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch>=2.0.0
pip install transformers>=4.35.0
pip install gradio>=4.0.0
pip install grpcio>=1.59.0
pip install plotly
pip install psutil pynvml
```

**å¯é€‰ä¼˜åŒ–**ï¼ˆéœ€è¦ CUDAï¼‰:
```bash
pip install flash-attn --no-build-isolation
```

### 2. å¯åŠ¨åˆ†æ‹†æ¨¡å‹

#### æ­¥éª¤ 1: å¯åŠ¨æœåŠ¡ç«¯
åœ¨ç¬¬ä¸€ä¸ªç»ˆç«¯ï¼š
```bash
cd /Users/lhy/Desktop/Git/SL
./run_gpt2_server.sh
```

ç­‰å¾…çœ‹åˆ° "âœ“ æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥..." æç¤ºã€‚

#### æ­¥éª¤ 2: å¯åŠ¨å®¢æˆ·ç«¯
åœ¨ç¬¬äºŒä¸ªç»ˆç«¯ï¼š
```bash
cd /Users/lhy/Desktop/Git/SL
./run_gpt2_client.sh
```

#### æ­¥éª¤ 3: è®¿é—®ç•Œé¢
æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š**http://localhost:7860**

### 3. å¯åŠ¨å®Œæ•´æ¨¡å‹ï¼ˆå¯¹ç…§ç»„ï¼‰

åœ¨å•ç‹¬çš„ç»ˆç«¯ï¼š
```bash
cd /Users/lhy/Desktop/Git/SL
./run_gpt2_full.sh
```

è®¿é—®ï¼š**http://localhost:7861**

---

## ğŸŒ è¿œç¨‹æœåŠ¡å™¨é…ç½®

å¦‚æœè¦å°† Trunk æ¨¡å‹éƒ¨ç½²åˆ°è¿œç¨‹æœåŠ¡å™¨ï¼š

### åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Š
```bash
# å¯åŠ¨æœåŠ¡ç«¯ï¼ˆç›‘å¬æ‰€æœ‰ç½‘å¡ï¼‰
./run_gpt2_server.sh
```

### åœ¨æœ¬åœ°å®¢æˆ·ç«¯
```bash
# è®¾ç½®è¿œç¨‹æœåŠ¡å™¨åœ°å€
export GPT2_TRUNK_SERVER="<è¿œç¨‹IP>:50051"
./run_gpt2_client.sh
```

---

## ğŸ“Š åŠŸèƒ½ç‰¹æ€§

### åˆ†æ‹†å®¢æˆ·ç«¯ (ç«¯å£ 7860)

**Tab 1: ğŸ“ æ–‡æœ¬ç”Ÿæˆ**
- è¾“å…¥æç¤ºè¯ç”Ÿæˆæ–‡æœ¬
- å¯è°ƒå‚æ•°ï¼šmax_tokens, temperature, top_k
- å®æ—¶æµå¼è¾“å‡º
- è¯¦ç»†çš„ç”Ÿæˆç»Ÿè®¡ï¼ˆtokens/sã€å»¶è¿Ÿç­‰ï¼‰

**Tab 2: ğŸ“Š æœåŠ¡ç«¯ç›‘æ§**
- å®æ—¶æ˜¾ç¤ºæœåŠ¡ç«¯ CPU/GPU/å†…å­˜ä½¿ç”¨æƒ…å†µ
- æ¯ 2 ç§’è‡ªåŠ¨åˆ·æ–°
- æ˜¾ç¤ºæœ€è¿‘ 10 æ¡ç›‘æ§å†å²

**Tab 3: â±ï¸ å»¶è¿Ÿåˆ†æ**
- Token ç”Ÿæˆå»¶è¿Ÿç»Ÿè®¡è¡¨
- å»¶è¿Ÿåˆ†å¸ƒç›´æ–¹å›¾
- Token ç”Ÿæˆæ—¶é—´çº¿å›¾
- æ¯ 5 ç§’è‡ªåŠ¨åˆ·æ–°

### å®Œæ•´æ¨¡å‹ (ç«¯å£ 7861)

**Tab 1: ğŸ“ æ–‡æœ¬ç”Ÿæˆ**
- ä¸åˆ†æ‹†å®¢æˆ·ç«¯ç›¸åŒçš„ç”ŸæˆåŠŸèƒ½
- ç”¨äºæ€§èƒ½å¯¹æ¯”

**Tab 2: ğŸ“Š æ€§èƒ½ç»Ÿè®¡**
- å»¶è¿Ÿç»Ÿè®¡æ‘˜è¦
- å»¶è¿Ÿåˆ†å¸ƒå’Œæ—¶é—´çº¿å›¾è¡¨

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å·²é›†æˆçš„ä¼˜åŒ–
1. **KV Cache**: è‡ªå›å½’ç”ŸæˆåŠ é€Ÿï¼ˆ2-3xï¼‰
2. **torch.compile()**: PyTorch 2.0 ç¼–è¯‘ä¼˜åŒ–ï¼ˆ10-30%æå‡ï¼‰
3. **Flash Attention**: æ³¨æ„åŠ›è®¡ç®—ä¼˜åŒ–ï¼ˆéœ€å®‰è£…ï¼‰

### é¢„æœŸæ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å®Œæ•´æ¨¡å‹ | åˆ†æ‹†æ¨¡å‹ (æœ¬åœ°) | åˆ†æ‹†æ¨¡å‹ (è¿œç¨‹) |
|------|---------|---------------|---------------|
| é¦– Token å»¶è¿Ÿ | ~50ms | ~80ms | ~200ms |
| åç»­ Token å»¶è¿Ÿ | ~20ms | ~35ms | ~100ms |
| ååé‡ (tokens/s) | ~50 | ~28 | ~10 |

---

## ğŸ“ æ—¥å¿—æŸ¥çœ‹

### å®æ—¶æŸ¥çœ‹æœåŠ¡ç«¯æ—¥å¿—
```bash
tail -f logs/gpt2_server.log
```

### å®æ—¶æŸ¥çœ‹å®¢æˆ·ç«¯æ—¥å¿—
```bash
tail -f logs/gpt2_client.log
```

### å®æ—¶æŸ¥çœ‹å®Œæ•´æ¨¡å‹æ—¥å¿—
```bash
tail -f logs/gpt2_full.log
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### 1. æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨
**ç—‡çŠ¶**: å®¢æˆ·ç«¯æŠ¥é”™ "æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨"

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æœåŠ¡ç«¯æ˜¯å¦æ­£å¸¸è¿è¡Œ
- æ£€æŸ¥ç«¯å£ 50051 æ˜¯å¦è¢«å ç”¨ï¼š`lsof -i:50051`
- æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
- ç¡®è®¤ `GPT2_TRUNK_SERVER` ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®

### 2. æ¨¡å‹åŠ è½½å¤±è´¥
**ç—‡çŠ¶**: "Failed to load model"

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®ä¿æœ‰ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä¼šä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼‰
- æ£€æŸ¥ `./models` ç›®å½•æ˜¯å¦æœ‰å†™æƒé™
- æ¸…ç©ºç¼“å­˜åé‡è¯•ï¼š`rm -rf ./models/gpt2`

### 3. GPU å†…å­˜ä¸è¶³
**ç—‡çŠ¶**: "CUDA out of memory"

**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨ CPU è¿è¡Œï¼šæ³¨é‡Šæ‰ `CUDA_VISIBLE_DEVICES` ç¯å¢ƒå˜é‡
- æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹

### 4. torch.compile() æŠ¥é”™
**ç—‡çŠ¶**: "torch.compile() failed"

**è§£å†³æ–¹æ¡ˆ**:
- è¿™æ˜¯å¯é€‰ä¼˜åŒ–ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å›é€€åˆ°æœªç¼–è¯‘ç‰ˆæœ¬
- éœ€è¦ PyTorch >= 2.0.0

---

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### KV Cache æ•°æ®æµ
```
é¦–æ¬¡è¯·æ±‚: Input Prompt (å®Œæ•´åºåˆ—)
    â†“
Bottom â†’ Trunk â†’ Top â†’ Token 1
    â†“
è¿”å›: present_key_values (8å±‚ï¼Œæ¯å±‚æœ‰ key å’Œ value)

åç»­è¯·æ±‚: æ–° Token
    â†“
Bottom â†’ Trunk (ä½¿ç”¨ past_key_values) â†’ Top â†’ Token 2
    â†“
æ›´æ–°: present_key_values
```

### gRPC æ¶ˆæ¯æ ¼å¼
- **ComputeRequest**: åŒ…å« tensor dataã€shapeã€past_key_values
- **ComputeResponse**: è¿”å› tensor dataã€shapeã€present_key_valuesã€compute_time

### ç›‘æ§æ•°æ®æµ
```
æœåŠ¡ç«¯ (æ¯1-2ç§’) â†’ gRPC Stream â†’ å®¢æˆ·ç«¯ â†’ Gradio UIæ›´æ–°
```

---

## ğŸ“– ç¤ºä¾‹ç”¨æ³•

### åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
```
Prompt: "Once upon a time"
Temperature: 1.0
Top-K: 50
Max tokens: 50
```

### ä½æ¸©åº¦ç”Ÿæˆï¼ˆæ›´ç¡®å®šæ€§ï¼‰
```
Prompt: "The future of AI is"
Temperature: 0.7
Top-K: 40
Max tokens: 100
```

### è´ªå©ªè§£ç 
```
Temperature: 0.0
Top-K: 0
```

---

## ğŸ¤ è´¡çŒ®

æœ¬é¡¹ç›®åŸºäºï¼š
- [SplitLearnCore](./SplitLearnCore/) - æ¨¡å‹æ‹†åˆ†æ ¸å¿ƒåº“
- [SplitLearnComm](./SplitLearnComm/) - gRPC é€šä¿¡åº“

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ™‹ å¸¸è§é—®é¢˜

**Q: åˆ†æ‹†æ¨¡å‹æ¯”å®Œæ•´æ¨¡å‹æ…¢å¤šå°‘ï¼Ÿ**
A: æœ¬åœ°ç½‘ç»œä¸‹çº¦æ…¢ 60-75%ï¼Œä¸»è¦å¼€é”€æ¥è‡ªç½‘ç»œå¾€è¿”æ—¶é—´ã€‚

**Q: å¯ä»¥ç”¨å…¶ä»–æ¨¡å‹å—ï¼Ÿ**
A: æ˜¯çš„ï¼Œåªéœ€ä¿®æ”¹ `model_id` å˜é‡ï¼Œä¾‹å¦‚ "gpt2-medium"ã€‚

**Q: Flash Attention æ˜¯å¿…é¡»çš„å—ï¼Ÿ**
A: ä¸æ˜¯ï¼Œè¿™æ˜¯å¯é€‰ä¼˜åŒ–ã€‚æ²¡æœ‰å®ƒç³»ç»Ÿä»èƒ½æ­£å¸¸è¿è¡Œã€‚

**Q: å¯ä»¥ä¿®æ”¹æ‹†åˆ†ç‚¹å—ï¼Ÿ**
A: å¯ä»¥ï¼Œä¿®æ”¹ `split_points = [2, 10]` ä¸ºå…¶ä»–å€¼ï¼Œä½†éœ€è¦ç¡®ä¿ï¼š
   - `0 < split_point_1 < split_point_2 < num_layers`
   - GPT-2 æœ‰ 12 å±‚ (num_layers=12)

---

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£æˆ–æäº¤ Issueã€‚
